<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>longgb246的博客</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-02-15T14:16:22.777Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>longgb246</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Seaborn-05-Pairplot多变量图</title>
    <link href="http://yoursite.com/2017/02/15/python_seaborn_05/"/>
    <id>http://yoursite.com/2017/02/15/python_seaborn_05/</id>
    <published>2017-02-15T14:15:55.000Z</published>
    <updated>2017-02-15T14:16:22.777Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#-*- coding:utf-8 -*-</div><div class="line">from __future__ import division</div><div class="line">import numpy as np</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import seaborn as sns</div></pre></td></tr></table></figure>
<h6 id="seaborn-pairplot-data-hue-None-hue-order-None-palette-None-vars-None-x-vars-None-y-vars-None-kind-’scatter’-diag-kind-’hist’-markers-None-size-2-5-aspect-1-dropna-True-plot-kws-None-diag-kws-None-grid-kws-None-¶"><a href="#seaborn-pairplot-data-hue-None-hue-order-None-palette-None-vars-None-x-vars-None-y-vars-None-kind-’scatter’-diag-kind-’hist’-markers-None-size-2-5-aspect-1-dropna-True-plot-kws-None-diag-kws-None-grid-kws-None-¶" class="headerlink" title="seaborn.pairplot(data, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind=’scatter’, diag_kind=’hist’, markers=None, size=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)¶"></a>seaborn.pairplot(data, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind=’scatter’, diag_kind=’hist’, markers=None, size=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)¶</h6><h6 id="数据指定："><a href="#数据指定：" class="headerlink" title="数据指定："></a>数据指定：</h6><blockquote>
<p>vars : 与data使用，否则使用data的全部变量。参数类型：numeric类型的变量list。<br>{x, y}_vars : 与data使用，否则使用data的全部变量。参数类型：numeric类型的变量list。<br>dropna : 是否剔除缺失值。参数类型：boolean, optional</p>
</blockquote>
<a id="more"></a>
<h6 id="特殊参数："><a href="#特殊参数：" class="headerlink" title="特殊参数："></a>特殊参数：</h6><blockquote>
<p>kind : {‘scatter’, ‘reg’}, optional Kind of plot for the non-identity relationships.<br>diag_kind : {‘hist’, ‘kde’}, optional。Kind of plot for the diagonal subplots.</p>
</blockquote>
<h6 id="基本参数："><a href="#基本参数：" class="headerlink" title="基本参数："></a>基本参数：</h6><blockquote>
<p>size : 默认 6，图的尺度大小（正方形）。参数类型：numeric<br>hue : 使用指定变量为分类变量画图。参数类型：string (变量名)<br>hue_order : list of strings Order for the levels of the hue variable in the palette<br>palette : 调色板颜色<br>markers : 使用不同的形状。参数类型：list<br>aspect : scalar, optional。Aspect * size gives the width (in inches) of each facet.<br>{plot, diag, grid}_kws : 指定其他参数。参数类型：dicts</p>
</blockquote>
<h6 id="返回："><a href="#返回：" class="headerlink" title="返回："></a>返回：</h6><blockquote>
<p>PairGrid 对象</p>
</blockquote>
<h3 id="1、散点图"><a href="#1、散点图" class="headerlink" title="1、散点图"></a>1、散点图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sns.set(style=&quot;ticks&quot;, color_codes=True)</div><div class="line">iris = sns.load_dataset(&quot;iris&quot;)</div><div class="line">g = sns.pairplot(iris)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-181c1bc96e6b849d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_01.png"></p>
<h3 id="2、指定分类变量的，散点图"><a href="#2、指定分类变量的，散点图" class="headerlink" title="2、指定分类变量的，散点图"></a>2、指定分类变量的，散点图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g2 = sns.pairplot(iris, hue=&quot;species&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-8559927b17853637.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_05.png"></p>
<h6 id="使用调色板"><a href="#使用调色板" class="headerlink" title="使用调色板"></a>使用调色板</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g3 = sns.pairplot(iris, hue=&quot;species&quot;, palette=&quot;husl&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-1d90711f5aea821d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_06.png"></p>
<h6 id="使用不同的形状"><a href="#使用不同的形状" class="headerlink" title="使用不同的形状"></a>使用不同的形状</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g4 = sns.pairplot(iris, hue=&quot;species&quot;, markers=[&quot;o&quot;, &quot;s&quot;, &quot;D&quot;])</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-f3ffb05e902f1cbc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_07.png"></p>
<h3 id="3、改变对角图"><a href="#3、改变对角图" class="headerlink" title="3、改变对角图"></a>3、改变对角图</h3><h6 id="使用-KDE"><a href="#使用-KDE" class="headerlink" title="使用 KDE"></a>使用 KDE</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g5 = sns.pairplot(iris, diag_kind=&quot;kde&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-ed62ebad7f83cf43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_03.png"></p>
<h6 id="使用回归"><a href="#使用回归" class="headerlink" title="使用回归"></a>使用回归</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g6 = sns.pairplot(iris, kind=&quot;reg&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-07d25cd26f686961.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_04.png"></p>
<h3 id="4、改变点形状，使用参数，使用-edgecolor"><a href="#4、改变点形状，使用参数，使用-edgecolor" class="headerlink" title="4、改变点形状，使用参数，使用 edgecolor"></a>4、改变点形状，使用参数，使用 edgecolor</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">g7 = sns.pairplot(iris, diag_kind=&quot;kde&quot;, markers=&quot;+&quot;,</div><div class="line">                  plot_kws=dict(s=50, edgecolor=&quot;b&quot;, linewidth=1),</div><div class="line">                  diag_kws=dict(shade=True))</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-b2772de52bdcf453.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="05_02.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#-*- coding:utf-8 -*-&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from __future__ import division&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import numpy as np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import seaborn as sns&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h6 id=&quot;seaborn-pairplot-data-hue-None-hue-order-None-palette-None-vars-None-x-vars-None-y-vars-None-kind-’scatter’-diag-kind-’hist’-markers-None-size-2-5-aspect-1-dropna-True-plot-kws-None-diag-kws-None-grid-kws-None-¶&quot;&gt;&lt;a href=&quot;#seaborn-pairplot-data-hue-None-hue-order-None-palette-None-vars-None-x-vars-None-y-vars-None-kind-’scatter’-diag-kind-’hist’-markers-None-size-2-5-aspect-1-dropna-True-plot-kws-None-diag-kws-None-grid-kws-None-¶&quot; class=&quot;headerlink&quot; title=&quot;seaborn.pairplot(data, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind=’scatter’, diag_kind=’hist’, markers=None, size=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)¶&quot;&gt;&lt;/a&gt;seaborn.pairplot(data, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind=’scatter’, diag_kind=’hist’, markers=None, size=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)¶&lt;/h6&gt;&lt;h6 id=&quot;数据指定：&quot;&gt;&lt;a href=&quot;#数据指定：&quot; class=&quot;headerlink&quot; title=&quot;数据指定：&quot;&gt;&lt;/a&gt;数据指定：&lt;/h6&gt;&lt;blockquote&gt;
&lt;p&gt;vars : 与data使用，否则使用data的全部变量。参数类型：numeric类型的变量list。&lt;br&gt;{x, y}_vars : 与data使用，否则使用data的全部变量。参数类型：numeric类型的变量list。&lt;br&gt;dropna : 是否剔除缺失值。参数类型：boolean, optional&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="seaborn" scheme="http://yoursite.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>Seaborn-04-Jointplot两变量图</title>
    <link href="http://yoursite.com/2017/02/15/python_seaborn_04/"/>
    <id>http://yoursite.com/2017/02/15/python_seaborn_04/</id>
    <published>2017-02-15T14:15:11.000Z</published>
    <updated>2017-02-15T14:15:33.739Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#-*- coding:utf-8 -*-</div><div class="line">import numpy as np</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import seaborn as sns</div></pre></td></tr></table></figure>
<blockquote>
<p>绿色：#6AB27B<br>土色：#a27712<br>浅紫色：#8172B2<br>蓝色：#4C72B0<br>红色：#C44E52</p>
</blockquote>
<h6 id="用于2个变量的画图"><a href="#用于2个变量的画图" class="headerlink" title="用于2个变量的画图"></a>用于2个变量的画图</h6><h3 id="1、基本参数"><a href="#1、基本参数" class="headerlink" title="1、基本参数"></a>1、基本参数</h3><h6 id="seaborn-jointplot-x-y-data-None-kind-’scatter’-stat-func-color-None-size-6-ratio-5-space-0-2-dropna-True-xlim-None-ylim-None-joint-kws-None-marginal-kws-None-annot-kws-None-kwargs"><a href="#seaborn-jointplot-x-y-data-None-kind-’scatter’-stat-func-color-None-size-6-ratio-5-space-0-2-dropna-True-xlim-None-ylim-None-joint-kws-None-marginal-kws-None-annot-kws-None-kwargs" class="headerlink" title="seaborn.jointplot(x, y, data=None, kind=’scatter’, stat_func=, color=None, size=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs)"></a>seaborn.jointplot(x, y, data=None, kind=’scatter’, stat_func=<function pearsonr="">, color=None, size=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs)</function></h6><h6 id="特殊参数："><a href="#特殊参数：" class="headerlink" title="特殊参数："></a>特殊参数：</h6><blockquote>
<p>kind : { “scatter” | “reg” | “resid” | “kde” | “hex” }</p>
</blockquote>
<a id="more"></a>
<h6 id="基本："><a href="#基本：" class="headerlink" title="基本："></a>基本：</h6><blockquote>
<ul>
<li><strong>color</strong> : 颜色。参数类型： matplotlib color</li>
<li><strong>size</strong> : 默认 6，图的尺度大小（正方形）。参数类型：numeric</li>
<li><strong>ratio</strong> : 中心图与侧边图的比例，越大、中心图占比越大。参数类型：numeric</li>
<li><strong>space</strong> : 中心图与侧边图的间隔大小。参数类型：numeric</li>
<li><strong>s</strong> : 点的大小。参数类型：numeric</li>
<li><strong>linewidth</strong> : 线的宽度。参数类型：numeric</li>
<li><strong>edgecolor</strong> : 点的边界颜色，默认无色，可以重叠。”w”为白色。参数类型：matplotlib color</li>
<li><strong>{x, y}lim</strong> : x、y轴的范围。参数类型：two-tuples</li>
<li><strong>{joint, marginal, annot}_kws</strong> : dicts Additional keyword arguments for the plot components.<br>marginal_kws : 侧边图的信息。例如：dict(bins=15, rug=True)<br>annot_kws : 注释的信息。例如：dict(stat=”r”)</li>
</ul>
</blockquote>
<h6 id="返回："><a href="#返回：" class="headerlink" title="返回："></a>返回：</h6><blockquote>
<p>JointGrid 对象</p>
</blockquote>
<h3 id="2、散点图"><a href="#2、散点图" class="headerlink" title="2、散点图"></a>2、散点图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tips = sns.load_dataset(&quot;tips&quot;)</div><div class="line">g = sns.jointplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips)</div><div class="line">g2 = sns.jointplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, kind=&quot;scatter&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-f43e6e48d6c285e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_01.png"></p>
<h3 id="3、回归图"><a href="#3、回归图" class="headerlink" title="3、回归图"></a>3、回归图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g3 = sns.jointplot(&quot;total_bill&quot;, &quot;tip&quot;, data=tips, kind=&quot;reg&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-f3003fa2f0180d91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_02.png"></p>
<h3 id="4、六角图"><a href="#4、六角图" class="headerlink" title="4、六角图"></a>4、六角图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g4 = sns.jointplot(&quot;total_bill&quot;, &quot;tip&quot;, data=tips, kind=&quot;hex&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-2bd5e1bb06b446f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_03.png"></p>
<h3 id="5、KDE-图"><a href="#5、KDE-图" class="headerlink" title="5、KDE 图"></a>5、KDE 图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g5 = sns.jointplot(&quot;total_bill&quot;, &quot;tip&quot;, data=tips, kind=&quot;kde&quot;, space=0, color=&quot;#6AB27B&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-e7210214a7d0cb68.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_04.png"></p>
<h3 id="6、分类变量与连续变量的图"><a href="#6、分类变量与连续变量的图" class="headerlink" title="6、分类变量与连续变量的图"></a>6、分类变量与连续变量的图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g6 = sns.jointplot(&quot;size&quot;, &quot;total_bill&quot;, data=tips, color=&quot;#8172B2&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-b95ac898275ba486.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_05.png"></p>
<h3 id="7、图相交：散点图-KDE-图"><a href="#7、图相交：散点图-KDE-图" class="headerlink" title="7、图相交：散点图+KDE 图"></a>7、图相交：散点图+KDE 图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iris = sns.load_dataset(&quot;iris&quot;)</div><div class="line">g7 = (sns.jointplot(&quot;sepal_length&quot;, &quot;sepal_width&quot;, data=iris, color=&quot;k&quot;)</div><div class="line">      .plot_joint(sns.kdeplot, zorder=0, n_levels=6))</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-64668b06f530d875.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_06.png"></p>
<h3 id="8、使用参数的画图"><a href="#8、使用参数的画图" class="headerlink" title="8、使用参数的画图"></a>8、使用参数的画图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">g8 = sns.jointplot(&quot;petal_length&quot;, &quot;sepal_length&quot;, data=iris, marginal_kws=dict(bins=15, rug=True), </div><div class="line">                    annot_kws=dict(stat=&quot;r&quot;), s=40, edgecolor=&quot;w&quot;, linewidth=1)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-ce045f48042cf4b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="04_07.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#-*- coding:utf-8 -*-&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import numpy as np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import seaborn as sns&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;绿色：#6AB27B&lt;br&gt;土色：#a27712&lt;br&gt;浅紫色：#8172B2&lt;br&gt;蓝色：#4C72B0&lt;br&gt;红色：#C44E52&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;用于2个变量的画图&quot;&gt;&lt;a href=&quot;#用于2个变量的画图&quot; class=&quot;headerlink&quot; title=&quot;用于2个变量的画图&quot;&gt;&lt;/a&gt;用于2个变量的画图&lt;/h6&gt;&lt;h3 id=&quot;1、基本参数&quot;&gt;&lt;a href=&quot;#1、基本参数&quot; class=&quot;headerlink&quot; title=&quot;1、基本参数&quot;&gt;&lt;/a&gt;1、基本参数&lt;/h3&gt;&lt;h6 id=&quot;seaborn-jointplot-x-y-data-None-kind-’scatter’-stat-func-color-None-size-6-ratio-5-space-0-2-dropna-True-xlim-None-ylim-None-joint-kws-None-marginal-kws-None-annot-kws-None-kwargs&quot;&gt;&lt;a href=&quot;#seaborn-jointplot-x-y-data-None-kind-’scatter’-stat-func-color-None-size-6-ratio-5-space-0-2-dropna-True-xlim-None-ylim-None-joint-kws-None-marginal-kws-None-annot-kws-None-kwargs&quot; class=&quot;headerlink&quot; title=&quot;seaborn.jointplot(x, y, data=None, kind=’scatter’, stat_func=, color=None, size=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs)&quot;&gt;&lt;/a&gt;seaborn.jointplot(x, y, data=None, kind=’scatter’, stat_func=&lt;function pearsonr&gt;, color=None, size=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs)&lt;/h6&gt;&lt;h6 id=&quot;特殊参数：&quot;&gt;&lt;a href=&quot;#特殊参数：&quot; class=&quot;headerlink&quot; title=&quot;特殊参数：&quot;&gt;&lt;/a&gt;特殊参数：&lt;/h6&gt;&lt;blockquote&gt;
&lt;p&gt;kind : { “scatter” | “reg” | “resid” | “kde” | “hex” }&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="seaborn" scheme="http://yoursite.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>Seaborn-03-数据分布图</title>
    <link href="http://yoursite.com/2017/02/15/python_seaborn_03/"/>
    <id>http://yoursite.com/2017/02/15/python_seaborn_03/</id>
    <published>2017-02-15T14:14:31.000Z</published>
    <updated>2017-02-15T14:14:50.510Z</updated>
    
    <content type="html"><![CDATA[<p>基本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#-*- coding:utf-8 -*-</div><div class="line">from __future__ import division</div><div class="line">import numpy as np</div><div class="line">import pandas as pd</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">from scipy import stats, integrate</div><div class="line">import seaborn as sns</div></pre></td></tr></table></figure></p>
<h3 id="1、快速查看分布"><a href="#1、快速查看分布" class="headerlink" title="1、快速查看分布"></a>1、快速查看分布</h3><h4 id="distplot"><a href="#distplot" class="headerlink" title="distplot"></a>distplot</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">x = np.random.randint(0,10,100)</div><div class="line">sns.distplot(x, color=&quot;b&quot;, bins=10, rug=True)</div><div class="line">sns.distplot(x, hist=False)</div></pre></td></tr></table></figure>
<a id="more"></a>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-b89b83c8e075b293.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_01.png"></p>
<h3 id="2、画单变量图"><a href="#2、画单变量图" class="headerlink" title="2、画单变量图"></a>2、画单变量图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">x = np.random.normal(0, 1, size=30)</div><div class="line">bandwidth = 1.06 * x.std() * x.size ** (-1 / 5.)  # 带宽计算公式</div><div class="line">support = np.linspace(-4, 4, 200)</div><div class="line">kernels = []</div><div class="line">for x_i in x:</div><div class="line">    kernel = stats.norm(x_i, bandwidth).pdf(support)</div><div class="line">    kernels.append(kernel)</div><div class="line">    plt.plot(support, kernel, color=&quot;#C55458&quot;)</div><div class="line">sns.rugplot(x, color=&quot;.2&quot;, linewidth=3)</div><div class="line"></div><div class="line">density = np.sum(kernels, axis=0)</div><div class="line">density /= integrate.trapz(density, support)</div><div class="line">plt.plot(support, density)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-e9abe996d9b5a196.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_02.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sns.kdeplot(x, shade=True)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-462f6ba92f868c6a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_03.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sns.kdeplot(x)</div><div class="line">sns.kdeplot(x, bw=.2, label=&quot;bw: 0.2&quot;)</div><div class="line">sns.kdeplot(x, bw=2, label=&quot;bw: 2&quot;)</div><div class="line">plt.legend()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-29d0b51e8a3e97f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_04.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">x = np.random.gamma(6, size=200)</div><div class="line">sns.distplot(x)</div><div class="line">sns.distplot(x, label=&apos;kde&apos;, hist=False)</div><div class="line">sns.distplot(x, kde=False, fit=stats.gamma, label=&apos;fit-gamma&apos;, hist=False)</div><div class="line">plt.legend()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-d50c8a44adebce08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_05.png"></p>
<h3 id="3、画二元变量分布图"><a href="#3、画二元变量分布图" class="headerlink" title="3、画二元变量分布图"></a>3、画二元变量分布图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mean, cov = [0, 1], [[1, .5], [.5, 1]]</div><div class="line">data = np.random.multivariate_normal(mean, cov, 200)</div><div class="line">df = pd.DataFrame(data, columns=[&quot;x&quot;, &quot;y&quot;])</div></pre></td></tr></table></figure>
<h4 id="（1）散点图"><a href="#（1）散点图" class="headerlink" title="（1）散点图"></a>（1）散点图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df, stat_func=stats.pearsonr)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-ddb078aa4e32167d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_06.png"></p>
<h4 id="（2）六边图"><a href="#（2）六边图" class="headerlink" title="（2）六边图"></a>（2）六边图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">data2 = np.random.multivariate_normal(mean, cov, 1000)</div><div class="line">df2 = pd.DataFrame(data2, columns=[&quot;x&quot;, &quot;y&quot;])</div><div class="line">with sns.axes_style(&quot;white&quot;):</div><div class="line">    sns.jointplot(x=df2[&quot;x&quot;], y=df2[&quot;y&quot;], kind=&quot;hex&quot;, color=&quot;k&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-f5c96ece9537f5e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_061.png"></p>
<h4 id="（3）相交的-KDE-图"><a href="#（3）相交的-KDE-图" class="headerlink" title="（3）相交的 KDE 图"></a>（3）相交的 KDE 图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df2, kind=&quot;kde&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-67048aed50daf655.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_07.png"></p>
<h4 id="（4）地毯图的-KDE-图"><a href="#（4）地毯图的-KDE-图" class="headerlink" title="（4）地毯图的 KDE 图"></a>（4）地毯图的 KDE 图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">f, ax = plt.subplots(figsize=(6, 6))</div><div class="line">sns.kdeplot(df2.x, df2.y, ax=ax)</div><div class="line">sns.rugplot(df2.x, color=&quot;#55A868&quot;, ax=ax)</div><div class="line">sns.rugplot(df2.y, vertical=True, ax=ax, color=&quot;#4C72B0&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-abe465425c2dea29.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_08.png"></p>
<h4 id="（5）星云图"><a href="#（5）星云图" class="headerlink" title="（5）星云图"></a>（5）星云图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">f2, ax = plt.subplots(figsize=(6, 6))</div><div class="line">cmap = sns.cubehelix_palette(as_cmap=True, dark=0, light=1, reverse=True)</div><div class="line">sns.kdeplot(df2.x, df2.y, cmap=cmap, n_levels=60, shade=True)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-f75cef380d74a948.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_09.png"></p>
<h4 id="（6）加入-图"><a href="#（6）加入-图" class="headerlink" title="（6）加入+图"></a>（6）加入+图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">g = sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df, kind=&quot;kde&quot;, color=&quot;#988CBE&quot;)</div><div class="line">g.plot_joint(plt.scatter, c=&quot;w&quot;, s=30, linewidth=1, marker=&quot;+&quot;)</div><div class="line">g.ax_joint.collections[0].set_alpha(0)</div><div class="line">g.set_axis_labels(&quot;$X$&quot;, &quot;$Y$&quot;)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-9465a07b8bd675b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_10.png"></p>
<h4 id="（7）画出两两变量散点图"><a href="#（7）画出两两变量散点图" class="headerlink" title="（7）画出两两变量散点图"></a>（7）画出两两变量散点图</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iris = sns.load_dataset(&quot;iris&quot;)</div><div class="line">sns.pairplot(iris)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-8cd800f2b92253f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_11.png"></p>
<h4 id="（8）画联合核函数"><a href="#（8）画联合核函数" class="headerlink" title="（8）画联合核函数"></a>（8）画联合核函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">g = sns.PairGrid(iris)</div><div class="line">g.map_diag(sns.kdeplot)</div><div class="line">g.map_offdiag(sns.kdeplot, cmap=&quot;Blues_d&quot;, n_levels=6)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-4134093336d7cd38.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="03_12.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基本&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#-*- coding:utf-8 -*-&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from __future__ import division&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import numpy as np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import pandas as pd&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from scipy import stats, integrate&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import seaborn as sns&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;1、快速查看分布&quot;&gt;&lt;a href=&quot;#1、快速查看分布&quot; class=&quot;headerlink&quot; title=&quot;1、快速查看分布&quot;&gt;&lt;/a&gt;1、快速查看分布&lt;/h3&gt;&lt;h4 id=&quot;distplot&quot;&gt;&lt;a href=&quot;#distplot&quot; class=&quot;headerlink&quot; title=&quot;distplot&quot;&gt;&lt;/a&gt;distplot&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;x = np.random.randint(0,10,100)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sns.distplot(x, color=&amp;quot;b&amp;quot;, bins=10, rug=True)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sns.distplot(x, hist=False)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="seaborn" scheme="http://yoursite.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>Seaborn-02-颜色板控制</title>
    <link href="http://yoursite.com/2017/02/15/python_seaborn_02/"/>
    <id>http://yoursite.com/2017/02/15/python_seaborn_02/</id>
    <published>2017-02-15T14:13:47.000Z</published>
    <updated>2017-02-15T14:14:08.514Z</updated>
    
    <content type="html"><![CDATA[<p>基本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#-*- coding:utf-8 -*-</div><div class="line">from __future__ import division</div><div class="line">import numpy as np</div><div class="line">import pandas as pd</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import seaborn as sns</div></pre></td></tr></table></figure></p>
<h3 id="1、定性调色板-Qualitative"><a href="#1、定性调色板-Qualitative" class="headerlink" title="1、定性调色板 Qualitative"></a>1、定性调色板 Qualitative</h3><p>默认的定性调色板：deep, muted, pastel, bright, dark, colorblind.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">current_palette = sns.color_palette()</div><div class="line">sns.palplot(current_palette)</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-1edf678b94171821.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_01.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">current_palette = sns.color_palette(&quot;pastel&quot;)</div><div class="line">sns.palplot(current_palette)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-c6d1c2e81741aeca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_02.png"></p>
<h3 id="2、使用环形调色板"><a href="#2、使用环形调色板" class="headerlink" title="2、使用环形调色板"></a>2、使用环形调色板</h3><p>画出均匀色带的颜色（改变颜色，但是保持色彩的亮度和饱和度）<br>hls_palette : h(hue)l(lightness)s(saturation)，均在0-1之间<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.hls_palette(8, l=.3, s=.8))</div><div class="line">sns.palplot(sns.husl_palette(8, l=.3, s=.8))</div></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-3233dfe757526f97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_03.png"></p>
<h3 id="3、自定义一个RGB颜色带"><a href="#3、自定义一个RGB颜色带" class="headerlink" title="3、自定义一个RGB颜色带"></a>3、自定义一个RGB颜色带</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">flatui = [&quot;#9b59b6&quot;, &quot;#3498db&quot;, &quot;#95a5a6&quot;, &quot;#e74c3c&quot;, &quot;#34495e&quot;, &quot;#2ecc71&quot;]</div><div class="line">sns.palplot(sns.color_palette(flatui))</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-a6c6ff1fb4458537.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_041.png"></p>
<h3 id="4、序列颜色-Sequential"><a href="#4、序列颜色-Sequential" class="headerlink" title="4、序列颜色 Sequential"></a>4、序列颜色 Sequential</h3><p>cubehelix_palette<br>最好：start0~3,rot-1~1<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.cubehelix_palette(8, start=.5, rot=-.75))</div><div class="line">sns.palplot(sns.cubehelix_palette(8, start=1.2, rot=.01))</div></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-d9bc2fe3a7776ef3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_04.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.cubehelix_palette(8, start=2, rot=0, dark=0, light=.95, reverse=True))</div><div class="line">sns.palplot(sns.cubehelix_palette(8, start=2, rot=0.05, reverse=True))</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-95bc29fc86a5c993.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_05.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">x, y = np.random.multivariate_normal([0, 0], [[1, -.5], [-.5, 1]], size=300).T</div><div class="line">cmap = sns.cubehelix_palette(light=1, as_cmap=True)</div><div class="line">sns.kdeplot(x, y, cmap=cmap, shade=True)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-56ec80c2777281fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_06.png"></p>
<p>light_palette、dark_palette 两种颜色调，渐亮、渐暗<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.light_palette(&quot;green&quot;))</div><div class="line">sns.palplot(sns.light_palette(&quot;#000000&quot;))</div></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-dc3f7802e7c0bfd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_07.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.dark_palette(&quot;purple&quot;))</div><div class="line">sns.palplot(sns.dark_palette(&quot;#a27712&quot;))</div><div class="line"></div><div class="line">pal = sns.dark_palette(&quot;palegreen&quot;, as_cmap=True)</div><div class="line">sns.kdeplot(x, y, cmap=pal)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-ed0c05e2b01bdb7c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_08.png"></p>
<h3 id="5、对称色调-diverging-palette"><a href="#5、对称色调-diverging-palette" class="headerlink" title="5、对称色调 diverging_palette"></a>5、对称色调 diverging_palette</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.diverging_palette(145, 280, s=85, l=25, n=7))</div><div class="line">sns.palplot(sns.diverging_palette(10, 220, sep=80, n=7))</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-20531fab569a2f65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_09.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sns.palplot(sns.diverging_palette(255, 133, l=60, n=7, center=&quot;dark&quot;))</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-af32f32b4e135c16.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_10.png"></p>
<h3 id="6、色调画图"><a href="#6、色调画图" class="headerlink" title="6、色调画图"></a>6、色调画图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def sinplot(flip=1):</div><div class="line">    x = np.linspace(0, 14, 100)</div><div class="line">    for i in range(1, 7):</div><div class="line">        plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip)</div><div class="line"></div><div class="line">sns.set_palette(&quot;husl&quot;)</div><div class="line">sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-4beb9956c1b753ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_11.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">with sns.color_palette(&quot;PuBuGn_d&quot;):</div><div class="line">    sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-71a718863be531c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_12.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">with sns.cubehelix_palette(8, start=1.2, rot=.01):</div><div class="line">    sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-126a28f82cd56368.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="02_13.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基本&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#-*- coding:utf-8 -*-&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from __future__ import division&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import numpy as np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import pandas as pd&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import seaborn as sns&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;1、定性调色板-Qualitative&quot;&gt;&lt;a href=&quot;#1、定性调色板-Qualitative&quot; class=&quot;headerlink&quot; title=&quot;1、定性调色板 Qualitative&quot;&gt;&lt;/a&gt;1、定性调色板 Qualitative&lt;/h3&gt;&lt;p&gt;默认的定性调色板：deep, muted, pastel, bright, dark, colorblind.&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;current_palette = sns.color_palette()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sns.palplot(current_palette)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="seaborn" scheme="http://yoursite.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>Seaborn-01-图控制</title>
    <link href="http://yoursite.com/2017/02/15/python_seaborn_01/"/>
    <id>http://yoursite.com/2017/02/15/python_seaborn_01/</id>
    <published>2017-02-15T14:12:53.000Z</published>
    <updated>2017-02-15T14:13:35.629Z</updated>
    
    <content type="html"><![CDATA[<p>基本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#-*- coding:utf-8 -*-</div><div class="line">import numpy as np</div><div class="line">import matplotlib as mpl</div><div class="line">import matplotlib.pyplot as plt</div></pre></td></tr></table></figure></p>
<h3 id="1、引入-seaborn-风格"><a href="#1、引入-seaborn-风格" class="headerlink" title="1、引入 seaborn 风格"></a>1、引入 seaborn 风格</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def sinplot(flip=1):</div><div class="line">    x = np.linspace(0, 14, 100)</div><div class="line">    for i in range(1, 7):</div><div class="line">        plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip)</div><div class="line">sinplot()</div></pre></td></tr></table></figure>
<a id="more"></a>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-3ceec96eb96978e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_01.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import seaborn as sns</div><div class="line">sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-9ff0fa621bafa8ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_02.png"></p>
<h3 id="2、预设主题：axes-style-和-set-style"><a href="#2、预设主题：axes-style-和-set-style" class="headerlink" title="2、预设主题：axes_style() 和 set_style()"></a>2、预设主题：axes_style() 和 set_style()</h3><p>darkgrid, whitegrid, dark, white, ticks，默认的是 darkgrid<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sns.set_style(&quot;whitegrid&quot;)</div><div class="line">data = np.random.normal(size=(20, 6)) + np.arange(6) / 2</div><div class="line">sns.boxplot(data=data)  # 箱型线</div></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-2532954fecba9ad0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_03.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.set_style(&quot;dark&quot;)</div><div class="line">sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-a5b49e81299d5fae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_04.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.set_style(&quot;white&quot;)</div><div class="line">sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-1ddf660d1d4c8a75.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_05.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.set_style(&quot;ticks&quot;)</div><div class="line">sinplot()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-2e3d411bd8416e4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_06.png"></p>
<h3 id="3、移除上框-despine"><a href="#3、移除上框-despine" class="headerlink" title="3、移除上框 despine()"></a>3、移除上框 despine()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sinplot()</div><div class="line">sns.despine()  # 默认移除上边框和右边框， despine(top=True, right=True, left=False, bottom = False)</div><div class="line">f, ax = plt.subplots()</div><div class="line">sns.violinplot(data=data)</div><div class="line">sns.despine(offset=10, trim=True)  # 坐标轴分离</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-71966ca31881bd6e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_08.png"></p>
<h3 id="4、暂时风格-axes-style-with"><a href="#4、暂时风格-axes-style-with" class="headerlink" title="4、暂时风格 axes_style() + with"></a>4、暂时风格 axes_style() + with</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">with sns.axes_style(&quot;darkgrid&quot;):</div><div class="line">    plt.subplot(211)</div><div class="line">    sinplot()</div><div class="line">plt.subplot(212)</div><div class="line">sinplot(-1)</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-ff01e178c0a8f5e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="01_07.png"></p>
<h3 id="5、自定义风格"><a href="#5、自定义风格" class="headerlink" title="5、自定义风格"></a>5、自定义风格</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sns.axes_style()  # 查看现有风格</div><div class="line">sns.set_style(&quot;darkgrid&quot;, &#123;&quot;axes.facecolor&quot;: &quot;.9&quot;&#125;)</div><div class="line">sinplot()</div><div class="line">sns.set_context(&quot;notebook&quot;, font_scale=1.5, rc=&#123;&quot;lines.linewidth&quot;: 2.5&#125;)</div><div class="line">sinplot()</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基本&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#-*- coding:utf-8 -*-&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import numpy as np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib as mpl&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;1、引入-seaborn-风格&quot;&gt;&lt;a href=&quot;#1、引入-seaborn-风格&quot; class=&quot;headerlink&quot; title=&quot;1、引入 seaborn 风格&quot;&gt;&lt;/a&gt;1、引入 seaborn 风格&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;def sinplot(flip=1):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    x = np.linspace(0, 14, 100)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    for i in range(1, 7):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sinplot()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="seaborn" scheme="http://yoursite.com/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>Pandas-office-10分钟开始</title>
    <link href="http://yoursite.com/2017/02/15/python_pandas_01/"/>
    <id>http://yoursite.com/2017/02/15/python_pandas_01/</id>
    <published>2017-02-15T14:12:37.000Z</published>
    <updated>2017-02-15T14:12:38.865Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基本"><a href="#基本" class="headerlink" title="基本"></a>基本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># -*- coding:utf-8 -*-</div><div class="line">import numpy as np</div><div class="line">import pandas as pd</div><div class="line">import matplotlib.pyplot as plt</div></pre></td></tr></table></figure>
<h3 id="1、创建数据框"><a href="#1、创建数据框" class="headerlink" title="1、创建数据框"></a>1、创建数据框</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">dates = pd.date_range(&apos;20130101&apos;, periods=6)</div><div class="line">df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(&apos;ABCD&apos;))</div><div class="line">left = pd.DataFrame(&#123;&apos;key&apos;: [&apos;foo&apos;, &apos;foo&apos;], &apos;lval&apos;: [1, 2]&#125;)</div><div class="line">right = pd.DataFrame(&#123;&apos;key&apos;: [&apos;foo&apos;, &apos;foo&apos;], &apos;rval&apos;: [4, 5]&#125;)</div></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="2、查看数据"><a href="#2、查看数据" class="headerlink" title="2、查看数据"></a>2、查看数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">df.head()</div><div class="line">df.tail(3)</div><div class="line">df.describe()</div><div class="line">df.T</div><div class="line">df.sort_index(axis=1, ascending=False)  # 按照行名、列名排列</div><div class="line">df.sort_values(by=&apos;B&apos;)</div></pre></td></tr></table></figure>
<h3 id="3、选择"><a href="#3、选择" class="headerlink" title="3、选择"></a>3、选择</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># .loc()</div><div class="line"># .iloc()</div></pre></td></tr></table></figure>
<h3 id="4、缺失值"><a href="#4、缺失值" class="headerlink" title="4、缺失值"></a>4、缺失值</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">df[&apos;E&apos;] = [1, 2, np.nan, 1, 2, np.nan]</div><div class="line">df.dropna(how=&apos;any&apos;)</div><div class="line">df.fillna(value=5)</div><div class="line">pd.isnull(df)</div></pre></td></tr></table></figure>
<h3 id="5、运用"><a href="#5、运用" class="headerlink" title="5、运用"></a>5、运用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.apply(np.cumsum)</div></pre></td></tr></table></figure>
<h3 id="6、交并"><a href="#6、交并" class="headerlink" title="6、交并"></a>6、交并</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">df = pd.DataFrame(np.random.randn(10, 4))</div><div class="line">pieces = [df[:3], df[3:7], df[7:]]</div><div class="line">pd.concat(pieces, axis=0)</div><div class="line">pd.concat([df, df], axis=1)</div><div class="line">pd.merge(left, right, on=&apos;key&apos;)</div><div class="line">left.merge(right, on=&apos;key&apos;)</div></pre></td></tr></table></figure>
<h3 id="7、groupby"><a href="#7、groupby" class="headerlink" title="7、groupby"></a>7、groupby</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">df = pd.DataFrame(&#123;&apos;A&apos;: [&apos;foo&apos;, &apos;bar&apos;, &apos;foo&apos;, &apos;bar&apos;, &apos;foo&apos;, &apos;bar&apos;, &apos;foo&apos;, &apos;foo&apos;],</div><div class="line">                   &apos;B&apos;: [&apos;one&apos;, &apos;one&apos;, &apos;two&apos;, &apos;three&apos;, &apos;two&apos;, &apos;two&apos;, &apos;one&apos;, &apos;three&apos;],</div><div class="line">                   &apos;C&apos;: np.random.randn(8),</div><div class="line">                   &apos;D&apos;: np.random.randn(8)&#125;)</div><div class="line">df.groupby(&apos;A&apos;).sum()</div><div class="line">df.groupby([&apos;A&apos;, &apos;B&apos;]).sum()</div></pre></td></tr></table></figure>
<h3 id="8、重组数据框"><a href="#8、重组数据框" class="headerlink" title="8、重组数据框"></a>8、重组数据框</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">tuples = list(zip(*[[&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;, &apos;qux&apos;, &apos;qux&apos;],</div><div class="line">                    [&apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;]]))</div><div class="line">index = pd.MultiIndex.from_tuples(tuples, names=[&apos;first&apos;, &apos;second&apos;])</div><div class="line">df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[&apos;A&apos;, &apos;B&apos;])</div><div class="line">df2 = df[:4]</div><div class="line">stacked = df2.stack()</div><div class="line">stacked.unstack()</div><div class="line">stacked.unstack(1)</div><div class="line">stacked.unstack(0)</div></pre></td></tr></table></figure>
<h3 id="Pivot-Tables"><a href="#Pivot-Tables" class="headerlink" title="Pivot Tables"></a>Pivot Tables</h3><h3 id="9、时间序列"><a href="#9、时间序列" class="headerlink" title="9、时间序列"></a>9、时间序列</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">rng = pd.date_range(&apos;1/1/2012&apos;, periods=100, freq=&apos;S&apos;)  # 按秒进行</div><div class="line">rng2 = pd.date_range(&apos;3/6/2012 00:00&apos;, periods=5, freq=&apos;D&apos;)  # 按天进行</div><div class="line">rng3 = pd.date_range(&apos;1/1/2012&apos;, periods=5, freq=&apos;M&apos;)  # 按月进行，保留天数</div><div class="line">ts = pd.Series(np.random.randn(len(rng3)), index=rng3)</div><div class="line">ps = ts.to_period()  # 天变为月，仅保留月数</div><div class="line">ps.to_timestamp()  # 月变为天</div><div class="line">prng = pd.period_range(&apos;1990Q1&apos;, &apos;2000Q4&apos;, freq=&apos;Q-NOV&apos;)  # 按季度进行</div><div class="line">ts = pd.Series(np.random.randn(len(prng)), prng)</div><div class="line">ts.index = (prng.asfreq(&apos;M&apos;, &apos;e&apos;) + 1).asfreq(&apos;H&apos;, &apos;s&apos;) + 9  # 季度转化为日期，指定时间</div></pre></td></tr></table></figure>
<h3 id="10、Categoricals-分类的使用"><a href="#10、Categoricals-分类的使用" class="headerlink" title="10、Categoricals 分类的使用"></a>10、Categoricals 分类的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">df = pd.DataFrame(&#123;&quot;id&quot;: [1, 2, 3, 4, 5, 6], &quot;raw_grade&quot;: [&apos;a&apos;, &apos;b&apos;, &apos;b&apos;, &apos;a&apos;, &apos;a&apos;, &apos;e&apos;]&#125;)</div><div class="line">df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;)</div><div class="line">df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;]</div><div class="line">df[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories([&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;])</div><div class="line">df.sort_values(by=&quot;grade&quot;)df.groupby(&quot;grade&quot;).size()</div></pre></td></tr></table></figure>
<h3 id="11、画图"><a href="#11、画图" class="headerlink" title="11、画图"></a>11、画图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ts = pd.Series(np.random.randn(1000), index=pd.date_range(&apos;1/1/2000&apos;, periods=1000))</div><div class="line">ts = ts.cumsum()</div><div class="line">ts.plot()</div><div class="line">df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=[&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df = df.cumsum()df.plot(); plt.legend(loc=&apos;best&apos;)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基本&quot;&gt;&lt;a href=&quot;#基本&quot; class=&quot;headerlink&quot; title=&quot;基本&quot;&gt;&lt;/a&gt;基本&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# -*- coding:utf-8 -*-&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import numpy as np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import pandas as pd&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import matplotlib.pyplot as plt&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;1、创建数据框&quot;&gt;&lt;a href=&quot;#1、创建数据框&quot; class=&quot;headerlink&quot; title=&quot;1、创建数据框&quot;&gt;&lt;/a&gt;1、创建数据框&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;dates = pd.date_range(&amp;apos;20130101&amp;apos;, periods=6)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(&amp;apos;ABCD&amp;apos;))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;left = pd.DataFrame(&amp;#123;&amp;apos;key&amp;apos;: [&amp;apos;foo&amp;apos;, &amp;apos;foo&amp;apos;], &amp;apos;lval&amp;apos;: [1, 2]&amp;#125;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;right = pd.DataFrame(&amp;#123;&amp;apos;key&amp;apos;: [&amp;apos;foo&amp;apos;, &amp;apos;foo&amp;apos;], &amp;apos;rval&amp;apos;: [4, 5]&amp;#125;)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="pandas" scheme="http://yoursite.com/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>聚类分析（2）：其他问题与算法</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_cluster_02/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_cluster_02/</id>
    <published>2017-02-15T13:57:34.000Z</published>
    <updated>2017-02-15T13:59:27.084Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、数据、簇、聚类算法"><a href="#一、数据、簇、聚类算法" class="headerlink" title="一、数据、簇、聚类算法"></a>一、数据、簇、聚类算法</h3><h4 id="（1）数据特性"><a href="#（1）数据特性" class="headerlink" title="（1）数据特性"></a>（1）数据特性</h4><p>可能影响聚类分析的因素：<br>高维性、规模、稀疏性、噪声和离群点、尺度</p>
<h3 id="二、基于原型的聚类"><a href="#二、基于原型的聚类" class="headerlink" title="二、基于原型的聚类"></a>二、基于原型的聚类</h3><h4 id="（1）模糊聚类"><a href="#（1）模糊聚类" class="headerlink" title="（1）模糊聚类"></a>（1）模糊聚类</h4><h5 id="1、模糊集合"><a href="#1、模糊集合" class="headerlink" title="1、模糊集合"></a>1、模糊集合</h5><p>模糊集合论允许对象以 0 和 1 之间的某个隶属度隶属于一个集合。<br><a id="more"></a></p>
<h5 id="2、模糊簇"><a href="#2、模糊簇" class="headerlink" title="2、模糊簇"></a>2、模糊簇</h5><p>xi 为数据点集合，Ci 为模糊子集簇。</p>
<h6 id="xi-的权值"><a href="#xi-的权值" class="headerlink" title="xi 的权值"></a>xi 的权值</h6><p>给定xi的所有权值之和为 1：<br>$$ \sum_{j=1}^{k}w_{ij}=1$$</p>
<h6 id="Ci-的限制"><a href="#Ci-的限制" class="headerlink" title="Ci 的限制"></a>Ci 的限制</h6><p>每个 Ci 以非零权值至少包含一个点，但不以权值1包含所有点：<br>$$ 0&lt; \sum_{i=1}^{m}w_{ij} &lt; m$$</p>
<h5 id="3、模糊-c-均值"><a href="#3、模糊-c-均值" class="headerlink" title="3、模糊 c 均值"></a>3、模糊 c 均值</h5><p>模糊 c 均值算法（FCM算法）</p>
<h6 id="算法："><a href="#算法：" class="headerlink" title="算法："></a>算法：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-2aba2e55df9606a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_19.png"></p>
<h6 id="目标函数："><a href="#目标函数：" class="headerlink" title="目标函数："></a>目标函数：</h6><p>计算SSE（误差平方和）：<br>$$ SSE(C_{1},C_{2},…,C_{k})=\sum_{j=1}^{k}\sum_{i=1}^{m}w_{ij}^{p}dist(x_{i},c_{j})^{2}$$</p>
<p>cj 是第 j 个簇的质心。</p>
<h6 id="初始化："><a href="#初始化：" class="headerlink" title="初始化："></a>初始化：</h6><p>随机初始化，但是限定求和为1.</p>
<h6 id="计算质心："><a href="#计算质心：" class="headerlink" title="计算质心："></a>计算质心：</h6><p>$$ c_{j}=\frac{\sum_{i=1}^{m}w_{ij}^{p}x_{i}}{\sum_{i=1}^{m}w_{ij}^{p}}$$</p>
<p>p为模糊权重，p=1时候，很想传统k均值，p越大，划分越模糊。一般选取p=2。</p>
<h6 id="更新模糊伪划分"><a href="#更新模糊伪划分" class="headerlink" title="更新模糊伪划分"></a>更新模糊伪划分</h6><p>当使用p时候，最小化SSE，可以推导出：<br>$$ w_{ij}=\frac{(\frac{1}{dist(x_{i},c_{j})^{2}})^{\frac{1}{p-1}}}{\sum_{q=1}^{k}(\frac{1}{dist(x_{i},c_{q})^{2}})^{\frac{1}{p-1}}}$$</p>
<p>当使用p=2的时候，公式得到简化：<br>$$ w_{ij}=\frac{\frac{1}{dist(x_{i},c_{j})^{2}}}{\sum_{q=1}^{k}\frac{1}{dist(x_{i},c_{q})^{2}}}$$</p>
<p>下面显示了一个模糊聚类的例子：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-5d5ed64fb7507a87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_20.png"></p>
<h6 id="4、优点与缺点"><a href="#4、优点与缺点" class="headerlink" title="4、优点与缺点"></a>4、优点与缺点</h6><p>与K均值相同的有点和缺点。</p>
<h4 id="（2）使用混合模型聚类"><a href="#（2）使用混合模型聚类" class="headerlink" title="（2）使用混合模型聚类"></a>（2）使用混合模型聚类</h4><h5 id="1、混合模型"><a href="#1、混合模型" class="headerlink" title="1、混合模型"></a>1、混合模型</h5><blockquote>
<p>混合模型将数据看作从不同的概率分布得到的观测值集合。其数据产生过程为，给定几个分布（通常类型相同，参数不同）随机的选择一个分布并由它产生一个对象，重复该过程m次。</p>
</blockquote>
<p>假定有 K 个分布和 m 个对象{x1,x2，…,xm}，\Theta 是参数的集合，则：<br>$$ prob(x_{i}|\theta _{j})$$<br>是第 i 个对象来自第 j 个分布的概率。<br>由于权值受限，其和为 1 。对于对象 x 的概率由公式给出：<br>$$ prob(x|\Theta)=\sum_{j=1}^{K}w_{j}p_{j}(x|\theta_{j})$$</p>
<p>如果对象以独立的方式产生，则对象集的概率是每个对象 xi 的概率的乘积。<br>$$ prob(\chi |\Theta)=\prod_{i=1}^{m}prob(x_{i}|\Theta)=\prod_{i=1}^{m}\sum_{j=1}^{K}w_{j}p_{j}(x_{i}|\theta_{j})$$</p>
<h6 id="混合高斯分布"><a href="#混合高斯分布" class="headerlink" title="混合高斯分布"></a>混合高斯分布</h6><p>假定有两个高斯分布，有相同的标准差 2，均值分别为 -4 和 4 。还假定每个分布以等概率选取，即为 w1=w2=0.5。公式为：<br>$$ prob(x|\Theta)=\frac{1}{2\sqrt{2\pi}}e^{-\frac{(x+4)^{2}}{8}}+\frac{1}{2\sqrt{2\pi}}e^{-\frac{(x-4)^{2}}{8}}$$</p>
<p>则该模型产生的 20000 个点的直方图：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-99cb7d254f7a3627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_21.png"></p>
<h5 id="2、使用最大似然估计（MLE）"><a href="#2、使用最大似然估计（MLE）" class="headerlink" title="2、使用最大似然估计（MLE）"></a>2、使用最大似然估计（MLE）</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-f16962be7b86ed20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_22.png"></p>
<h5 id="3、使用-EM-算法"><a href="#3、使用-EM-算法" class="headerlink" title="3、使用 EM 算法"></a>3、使用 EM 算法</h5><h6 id="EM-算法步骤："><a href="#EM-算法步骤：" class="headerlink" title="EM 算法步骤："></a>EM 算法步骤：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-9b2869bfd5df7b2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_23.png"></p>
<h6 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-78765db5e05add63.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_24.png"></p>
<h6 id="样本集上的EM："><a href="#样本集上的EM：" class="headerlink" title="样本集上的EM："></a>样本集上的EM：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-ed7f6abae0bc075b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_25.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-fa31354f6b1f2fb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_26.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-7d4182e4def81562.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_27.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-5181ec33aad7fc4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_28.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-536b5c7737f6a838.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_29.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-97ca406ad031203d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_30.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-c463110733506aa0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_31.png"></p>
<h6 id="4、EM算法在混合模型的优缺点"><a href="#4、EM算法在混合模型的优缺点" class="headerlink" title="4、EM算法在混合模型的优缺点"></a>4、EM算法在混合模型的优缺点</h6><p>缺点：</p>
<blockquote>
<p>1、EM算法可能很慢。<br>2、数据近似斜线性时候，不能很好处理。<br>3、混合模型在有噪声和离群点时，可能有问题。</p>
</blockquote>
<p>优点：</p>
<blockquote>
<p>1、混合模型比K均值或模糊c均值更一般。<br>2、可以发现不同大小和椭球状的簇。</p>
</blockquote>
<h4 id="（3）自组织映射"><a href="#（3）自组织映射" class="headerlink" title="（3）自组织映射"></a>（3）自组织映射</h4><p>自组织映射（SOFM或SOM）是一种基于神经网络观点的聚类和数据可视化技术。</p>
<p>[369-396=27]</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、数据、簇、聚类算法&quot;&gt;&lt;a href=&quot;#一、数据、簇、聚类算法&quot; class=&quot;headerlink&quot; title=&quot;一、数据、簇、聚类算法&quot;&gt;&lt;/a&gt;一、数据、簇、聚类算法&lt;/h3&gt;&lt;h4 id=&quot;（1）数据特性&quot;&gt;&lt;a href=&quot;#（1）数据特性&quot; class=&quot;headerlink&quot; title=&quot;（1）数据特性&quot;&gt;&lt;/a&gt;（1）数据特性&lt;/h4&gt;&lt;p&gt;可能影响聚类分析的因素：&lt;br&gt;高维性、规模、稀疏性、噪声和离群点、尺度&lt;/p&gt;
&lt;h3 id=&quot;二、基于原型的聚类&quot;&gt;&lt;a href=&quot;#二、基于原型的聚类&quot; class=&quot;headerlink&quot; title=&quot;二、基于原型的聚类&quot;&gt;&lt;/a&gt;二、基于原型的聚类&lt;/h3&gt;&lt;h4 id=&quot;（1）模糊聚类&quot;&gt;&lt;a href=&quot;#（1）模糊聚类&quot; class=&quot;headerlink&quot; title=&quot;（1）模糊聚类&quot;&gt;&lt;/a&gt;（1）模糊聚类&lt;/h4&gt;&lt;h5 id=&quot;1、模糊集合&quot;&gt;&lt;a href=&quot;#1、模糊集合&quot; class=&quot;headerlink&quot; title=&quot;1、模糊集合&quot;&gt;&lt;/a&gt;1、模糊集合&lt;/h5&gt;&lt;p&gt;模糊集合论允许对象以 0 和 1 之间的某个隶属度隶属于一个集合。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
      <category term="聚类算法" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>聚类分析（1）：基本概念和算法</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_cluster_01/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_cluster_01/</id>
    <published>2017-02-15T13:57:00.000Z</published>
    <updated>2017-02-15T13:58:13.382Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h3><h4 id="（1）聚类分析"><a href="#（1）聚类分析" class="headerlink" title="（1）聚类分析"></a>（1）聚类分析</h4><blockquote>
<p>目标是，分组数据使得，组内的对象是相似的（相关的），不同组是不同的（不相关的）。</p>
</blockquote>
<h4 id="（2）聚类类型"><a href="#（2）聚类类型" class="headerlink" title="（2）聚类类型"></a>（2）聚类类型</h4><h5 id="1、层次、划分"><a href="#1、层次、划分" class="headerlink" title="1、层次、划分"></a>1、层次、划分</h5><p>层次聚类（嵌套聚类，hierarchial clustering）：聚类簇组织成一棵树，每一个结点是其子女的并。<br>划分聚类（非嵌套聚类，partional clustering）：简单的将数据对象划分为不重叠的子集。</p>
<a id="more"></a>
<h5 id="2、互斥、重叠、模糊"><a href="#2、互斥、重叠、模糊" class="headerlink" title="2、互斥、重叠、模糊"></a>2、互斥、重叠、模糊</h5><p>互斥聚类（exclusive）：每个对象被指派到单独的单个簇。<br>重叠聚类（overlapping）：一个对象可以同时属于多个簇。<br>模糊聚类（fuzzy clustering）：概率聚类，每个对象以0-1之间的的权值隶属于一个类，但是每个对象的权值之和为1。</p>
<h5 id="3、完全、部分"><a href="#3、完全、部分" class="headerlink" title="3、完全、部分"></a>3、完全、部分</h5><p>完全聚类（complete clustering）：每个对象指派到一个类。<br>部分聚类（partial clustering）：某些对象可以不属于明确定义的类。</p>
<h4 id="（3）簇类型"><a href="#（3）簇类型" class="headerlink" title="（3）簇类型"></a>（3）簇类型</h4><p>下面显示一些簇类型：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-362b6fe658b6e41b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_01.png"></p>
<p>类型：明显分离、基于原型（中心簇）、基于图（连通）、基于密度、共同性质的（概念簇）。</p>
<h3 id="二、K-均值"><a href="#二、K-均值" class="headerlink" title="二、K-均值"></a>二、K-均值</h3><h4 id="（1）基本K-均值算法"><a href="#（1）基本K-均值算法" class="headerlink" title="（1）基本K-均值算法"></a>（1）基本K-均值算法</h4><h6 id="算法步骤："><a href="#算法步骤：" class="headerlink" title="算法步骤："></a>算法步骤：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-b5af82ded562398f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_02.png"></p>
<h6 id="目标函数："><a href="#目标函数：" class="headerlink" title="目标函数："></a>目标函数：</h6><p>$$ SSE=\sum_{i=1}^{K}\sum_{x\in C_{i}}dist(c_{i},x)^{2}, c_{i}=\frac{1}{m_{i}}\sum_{x\in C_{i}}x$$</p>
<p>上面的第3、4步骤试图最小化目标函数（SSE或者其他的），直到收敛。</p>
<h6 id="常见的邻近度和目标函数组合："><a href="#常见的邻近度和目标函数组合：" class="headerlink" title="常见的邻近度和目标函数组合："></a>常见的邻近度和目标函数组合：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-adfdc1d85292066b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_03.png"></p>
<h6 id="初始质心："><a href="#初始质心：" class="headerlink" title="初始质心："></a>初始质心：</h6><p>不同的初始质心会收敛到不同的结果。</p>
<blockquote>
<p>随机初始质心：问题是，即使运行多次也不一定能得到好的分类。因为，一旦一个簇内有多个质心，该簇很可能被分裂。<br>其他方法：先使用层次聚类，从中提取K个类，使用这K个类的质心作为初始质心。仅对：样本较小，K较小有效。</p>
</blockquote>
<h4 id="（2）K均值：附加问题"><a href="#（2）K均值：附加问题" class="headerlink" title="（2）K均值：附加问题"></a>（2）K均值：附加问题</h4><h6 id="处理空簇"><a href="#处理空簇" class="headerlink" title="处理空簇"></a>处理空簇</h6><p>所有的点没有一个分配到一个质心。选择替补质心。</p>
<h6 id="离群点"><a href="#离群点" class="headerlink" title="离群点"></a>离群点</h6><p>离群点对于k-均值聚类有较大影响，应该删除。</p>
<h6 id="后处理SSE"><a href="#后处理SSE" class="headerlink" title="后处理SSE"></a>后处理SSE</h6><p>增加簇：</p>
<blockquote>
<p>分裂一个簇：选择SSE最大的分裂。<br>引进一个新的质心：选择离所有质心最远的点。</p>
</blockquote>
<p>减少簇：</p>
<blockquote>
<p>拆散一个簇：删除簇的对应质心。簇中的点重新分配。<br>合并两个簇：选择两个质心最接近的两个簇合并。</p>
</blockquote>
<h6 id="增量的更新质心"><a href="#增量的更新质心" class="headerlink" title="增量的更新质心"></a>增量的更新质心</h6><p>给定一个目标函数，每步要零次或两次更新质心。<br>可能产生次序依赖性问题，开销也稍微大一些。</p>
<h4 id="（3）二分K均值"><a href="#（3）二分K均值" class="headerlink" title="（3）二分K均值"></a>（3）二分K均值</h4><p>思路：</p>
<blockquote>
<p>为了得到 K 个簇，将所有点分裂成两个簇，从这些簇中，选取一个继续分裂，直到产生 K 个簇。</p>
</blockquote>
<p>算法：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-2394e71761569cad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_04.png"></p>
<p>带分裂的簇选择方法有很多：最大的簇，最大SSE的簇等。</p>
<h4 id="（4）优点与缺点"><a href="#（4）优点与缺点" class="headerlink" title="（4）优点与缺点"></a>（4）优点与缺点</h4><p>优点：二分K均值，不太受初始值的影响。<br>缺点：不能处理非球形簇、不同尺寸、不同密度的簇。</p>
<h3 id="三、凝聚层次聚类"><a href="#三、凝聚层次聚类" class="headerlink" title="三、凝聚层次聚类"></a>三、凝聚层次聚类</h3><h4 id="（1）基本算法"><a href="#（1）基本算法" class="headerlink" title="（1）基本算法"></a>（1）基本算法</h4><p><img src="http://upload-images.jianshu.io/upload_images/3341358-8799159151edff4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_05.png"></p>
<h4 id="（2）距离的度量："><a href="#（2）距离的度量：" class="headerlink" title="（2）距离的度量："></a>（2）距离的度量：</h4><p>最短距离（min）、最长距离（max）、平均距离、ward和质心距离<br><img src="http://upload-images.jianshu.io/upload_images/3341358-03ba4bb8e8df0a7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_06.png"></p>
<h4 id="（3）簇邻近度的Lance-Williams公式"><a href="#（3）簇邻近度的Lance-Williams公式" class="headerlink" title="（3）簇邻近度的Lance-Williams公式"></a>（3）簇邻近度的Lance-Williams公式</h4><p>Lance-Williams公式：<br>$$p(R,Q)=\alpha_{A}p(A,Q)+ \alpha_{B}p(B,Q)+\beta p(A,B)+\gamma |p(A,Q)-p(B,Q)|$$</p>
<p>A、B、Q合并得到R。p(. , .)是邻近度函数，以上表示它们为线性函数。<br>下面是Lance-Williams公式鱼邻近度函数的对应：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-ae89f01f8ec66f28.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_07.png"></p>
<h4 id="（4）层次聚类的问题"><a href="#（4）层次聚类的问题" class="headerlink" title="（4）层次聚类的问题"></a>（4）层次聚类的问题</h4><blockquote>
<p>1、缺乏全局目标函数：避开了解决困难的组合优化问题，很难选择初始点的问题。<br>2、合并是最终的：一旦合并就不能撤销。</p>
</blockquote>
<h3 id="四、DBSCAN"><a href="#四、DBSCAN" class="headerlink" title="四、DBSCAN"></a>四、DBSCAN</h3><p>基于密度聚类算法，寻找被低密度区域分离的高密度区域。</p>
<h4 id="（1）传统密度：基于中心的方法"><a href="#（1）传统密度：基于中心的方法" class="headerlink" title="（1）传统密度：基于中心的方法"></a>（1）传统密度：基于中心的方法</h4><p><img src="http://upload-images.jianshu.io/upload_images/3341358-56563eca57abd2c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_08.png"></p>
<blockquote>
<p>核心点（core point）：该点给定邻域的点个数超过用户给定阈值 MinPts（Eps为用户定义的距离）。A点。<br>边界点（border point）：不是核心点，它落在某个核心点邻域。B点。<br>噪声点（noise point）：即非核心点也非边界点。C点。</p>
</blockquote>
<h4 id="（2）DBSCAN算法"><a href="#（2）DBSCAN算法" class="headerlink" title="（2）DBSCAN算法"></a>（2）DBSCAN算法</h4><h5 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h5><blockquote>
<p>任意两个足够近（Eps之内）的核心点将方到一个簇中。<br>任何与核心点足够近的边界点放到相同簇中（如果边界点靠近不同簇的核心点，要解决平均问题）。<br>噪声点丢弃。</p>
</blockquote>
<h5 id="算法步骤：-1"><a href="#算法步骤：-1" class="headerlink" title="算法步骤："></a>算法步骤：</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-d3eef169fea3e7a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_09.png"></p>
<h5 id="选择-Eps-和-MinPts"><a href="#选择-Eps-和-MinPts" class="headerlink" title="选择 Eps 和 MinPts"></a>选择 Eps 和 MinPts</h5><h6 id="使用-k-距离"><a href="#使用-k-距离" class="headerlink" title="使用 k-距离"></a>使用 k-距离</h6><p>k-最近邻的距离，对于某个k，计算所有点的k-距离，以递增排序，则k-距离会在某个部分急剧变化（噪声点的k-距离很大）。选取k为MinPts，合适的距离为Eps。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-5c7112fc9348f356.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_10.png"></p>
<p>下面为，使用Eps=10，MinPts=4的结果：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-877f018f6cc497ab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_11.png"></p>
<h4 id="（3）优点与缺点"><a href="#（3）优点与缺点" class="headerlink" title="（3）优点与缺点"></a>（3）优点与缺点</h4><blockquote>
<p>优点：对抗噪音的能力很强，能够处理任意形状和大小的簇。<br>缺点：DBSCAN当计算近邻的时候，开销很大。</p>
</blockquote>
<h3 id="五、簇评估"><a href="#五、簇评估" class="headerlink" title="五、簇评估"></a>五、簇评估</h3><h4 id="（1）非监督簇评估：凝聚度、分离度"><a href="#（1）非监督簇评估：凝聚度、分离度" class="headerlink" title="（1）非监督簇评估：凝聚度、分离度"></a>（1）非监督簇评估：凝聚度、分离度</h4><p>$$ overallValidity=\sum_{i=1}^{K}w_{i}validity(C_{i})$$<br>K个簇的有效性，为个体簇的有效性加权和，下面给出度量表：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-4f58d89f7cc1b7ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_12.png"></p>
<h5 id="1、基于图：凝聚度、分离度"><a href="#1、基于图：凝聚度、分离度" class="headerlink" title="1、基于图：凝聚度、分离度"></a>1、基于图：凝聚度、分离度</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-f1c03fc8f85479df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_13.png"></p>
<p>proximity函数可以是相似度、相异度，或者是这些量的简单函数：<br>$$ cohesion(C_{i})=\sum_{x\in C_{i},y\in C_{i}}proximity(x,y)$$<br>$$ separation(C_{i},C_{j})=\sum_{x\in C_{i},y\in C_{j}}proximity(x,y)$$</p>
<h5 id="2、基于原型：凝聚度、分离度"><a href="#2、基于原型：凝聚度、分离度" class="headerlink" title="2、基于原型：凝聚度、分离度"></a>2、基于原型：凝聚度、分离度</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-90f783db930011ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_14.png"></p>
<p>ci是Ci的原型（质心），c是总体原型（质心）：<br>$$ cohesion(C_{i})=\sum_{x\in C_{i}}proximity(x,c_{i})$$<br>$$ separation(C_{i},C_{j})=proximity(c_{i},c_{j})$$<br>$$ separation(C_{i})=proximity(c_{i},c)$$</p>
<h5 id="3、轮廓系数"><a href="#3、轮廓系数" class="headerlink" title="3、轮廓系数"></a>3、轮廓系数</h5><p>轮廓系数（silhouette coefficient）：</p>
<blockquote>
<p>1、对于第 i 个对象，计算它到所在簇所有点的平均距离：ai<br>2、对于第 i 个对象，计算它到不含它的其他簇所有对象的平均距离，找出最小的：bi<br>3、对于第 i 个对象，轮廓系数为：<br>$$s_{i}=\frac{(b_{i}-a_{i})}{max(a_{i},b_{i})}$$</p>
</blockquote>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-a14462398698aadd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_15.png"></p>
<h4 id="（3）非监督簇评估：近邻矩阵"><a href="#（3）非监督簇评估：近邻矩阵" class="headerlink" title="（3）非监督簇评估：近邻矩阵"></a>（3）非监督簇评估：近邻矩阵</h4><p><img src="http://upload-images.jianshu.io/upload_images/3341358-44f038f80f34a68d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_16.png"></p>
<p>可以使用某个距离度量法来度量相似度，得到每个点的距离，汇总得到近邻矩阵。但是仅使用于小数据、抽样。</p>
<h4 id="（4）簇个数"><a href="#（4）簇个数" class="headerlink" title="（4）簇个数"></a>（4）簇个数</h4><p><img src="http://upload-images.jianshu.io/upload_images/3341358-2f29fe272a86189f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_17.png"></p>
<p>使用 SSE 和轮廓系数来判断，统计上的 SSE 的说明性更强，统计上不止这一个系数可以分类。</p>
<h4 id="（5）聚类趋势"><a href="#（5）聚类趋势" class="headerlink" title="（5）聚类趋势"></a>（5）聚类趋势</h4><p>度量空间中的点是否为随机分布的，使用Hopkins统计量：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-fc559a752d89a1cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="8_18.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、概述&quot;&gt;&lt;a href=&quot;#一、概述&quot; class=&quot;headerlink&quot; title=&quot;一、概述&quot;&gt;&lt;/a&gt;一、概述&lt;/h3&gt;&lt;h4 id=&quot;（1）聚类分析&quot;&gt;&lt;a href=&quot;#（1）聚类分析&quot; class=&quot;headerlink&quot; title=&quot;（1）聚类分析&quot;&gt;&lt;/a&gt;（1）聚类分析&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;目标是，分组数据使得，组内的对象是相似的（相关的），不同组是不同的（不相关的）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;（2）聚类类型&quot;&gt;&lt;a href=&quot;#（2）聚类类型&quot; class=&quot;headerlink&quot; title=&quot;（2）聚类类型&quot;&gt;&lt;/a&gt;（2）聚类类型&lt;/h4&gt;&lt;h5 id=&quot;1、层次、划分&quot;&gt;&lt;a href=&quot;#1、层次、划分&quot; class=&quot;headerlink&quot; title=&quot;1、层次、划分&quot;&gt;&lt;/a&gt;1、层次、划分&lt;/h5&gt;&lt;p&gt;层次聚类（嵌套聚类，hierarchial clustering）：聚类簇组织成一棵树，每一个结点是其子女的并。&lt;br&gt;划分聚类（非嵌套聚类，partional clustering）：简单的将数据对象划分为不重叠的子集。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
      <category term="聚类算法" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>关联分析（2）：高级概念</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_realation_02/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_realation_02/</id>
    <published>2017-02-15T13:56:50.000Z</published>
    <updated>2017-02-15T13:56:52.045Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、处理分类属性"><a href="#一、处理分类属性" class="headerlink" title="一、处理分类属性"></a>一、处理分类属性</h3><p>依然使用虚拟变量。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-2656cf4ac104d32b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="7_01.png"></p>
<p>（1）属性值有可能不频繁，可以分组处理，使得较小数据合并。<br>（2）某些属性的频率出现比其他压高很多，出现冗余模式，可能需要剔除。</p>
<a id="more"></a>
<h3 id="二、处理连续变量"><a href="#二、处理连续变量" class="headerlink" title="二、处理连续变量"></a>二、处理连续变量</h3><h4 id="（1）基于离散化方法"><a href="#（1）基于离散化方法" class="headerlink" title="（1）基于离散化方法"></a>（1）基于离散化方法</h4><p>问题：区间宽度不好确定，计算开销比较大，提取许多冗余的规则。</p>
<h4 id="（2）基于统计学方法"><a href="#（2）基于统计学方法" class="headerlink" title="（2）基于统计学方法"></a>（2）基于统计学方法</h4><p>[略]</p>
<h4 id="（3）-非离散化方法"><a href="#（3）-非离散化方法" class="headerlink" title="（3） 非离散化方法"></a>（3） 非离散化方法</h4><p>[略]</p>
<h3 id="三、处理概念分层"><a href="#三、处理概念分层" class="headerlink" title="三、处理概念分层"></a>三、处理概念分层</h3><p>[略]</p>
<h3 id="四、序列模式"><a href="#四、序列模式" class="headerlink" title="四、序列模式"></a>四、序列模式</h3><p>[略]</p>
<h3 id="五、子图模式"><a href="#五、子图模式" class="headerlink" title="五、子图模式"></a>五、子图模式</h3><p>[略]</p>
<h3 id="六、非频繁模式"><a href="#六、非频繁模式" class="headerlink" title="六、非频繁模式"></a>六、非频繁模式</h3><p>[略]</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、处理分类属性&quot;&gt;&lt;a href=&quot;#一、处理分类属性&quot; class=&quot;headerlink&quot; title=&quot;一、处理分类属性&quot;&gt;&lt;/a&gt;一、处理分类属性&lt;/h3&gt;&lt;p&gt;依然使用虚拟变量。&lt;br&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/3341358-2656cf4ac104d32b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;7_01.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;（1）属性值有可能不频繁，可以分组处理，使得较小数据合并。&lt;br&gt;（2）某些属性的频率出现比其他压高很多，出现冗余模式，可能需要剔除。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
      <category term="关联分析" scheme="http://yoursite.com/tags/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>关联分析（1）：基本概念和算法</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_realation_01/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_realation_01/</id>
    <published>2017-02-15T13:48:51.000Z</published>
    <updated>2017-02-15T13:53:30.355Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h3><h5 id="（一）基本概念"><a href="#（一）基本概念" class="headerlink" title="（一）基本概念"></a>（一）基本概念</h5><h6 id="二元概念"><a href="#二元概念" class="headerlink" title="二元概念"></a>二元概念</h6><p>对于购物篮数据，使用二元变量表示。1表示购买，0表示没有购买。</p>
<h6 id="项集和支持度计数"><a href="#项集和支持度计数" class="headerlink" title="项集和支持度计数"></a>项集和支持度计数</h6><p>事务：一行数据。<br>k-项集：一个事务中，出现项。如：3-项集，{啤酒，尿布，牛奶}<br><img src="http://upload-images.jianshu.io/upload_images/3341358-11295870eaafecad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_01.png"></p>
<p>支持度计数：<br>$$\sigma (X)=|\left \{ t_{i}|X\subseteq t_{i},t_{i}\in T \right \}|$$</p>
<p>如，上式中，项集{啤酒，尿布，牛奶}的支持度计数为2，因为只有2个事务同时包含3个项。</p>
<a id="more"></a>
<h6 id="关联规则（association-rule）"><a href="#关联规则（association-rule）" class="headerlink" title="关联规则（association rule）"></a>关联规则（association rule）</h6><p>关于 X、Y 的关联规则，支持度、置信度的定义如下：<br>$$s(X\rightarrow Y)=\frac{\sigma (X\cup Y)}{N}$$<br>$$s(X\rightarrow Y)=\frac{\sigma (X\cup Y)}{\sigma (X)}$$</p>
<p>例如：X{牛奶，尿布}，Y{啤酒}，则并集{牛奶，尿布，啤酒}的支持度计数为2，N为事务总数5，所以支持度=2/5=0.4。X 的支持度=3，所以置信度为2/3=0.67。</p>
<p>支持度很低的规则可能只是偶然出现，低的支持度计数也是无意义的。支持度通常用于删去无意义的规则，<br>置信度越高，表示Y在包含X的事务中出现的可能性较大。Y也可以用于估计在给定X的条件下的条件概率。</p>
<h5 id="（二）关联规则挖掘"><a href="#（二）关联规则挖掘" class="headerlink" title="（二）关联规则挖掘"></a>（二）关联规则挖掘</h5><blockquote>
<p>1、频繁项集产生：发现满足最小支持度阈值的所有项集，这些项是频繁项集。<br>2、规则产生：从频繁项集中提取所有高置信度规则，这些规则是强规则。</p>
</blockquote>
<h5 id="（三）频繁项集的产生"><a href="#（三）频繁项集的产生" class="headerlink" title="（三）频繁项集的产生"></a>（三）频繁项集的产生</h5><p>格结构（lattice structure）：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-f927df9a115283bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_02.png"></p>
<h5 id="原始方法："><a href="#原始方法：" class="headerlink" title="原始方法："></a>原始方法：</h5><p>遍历每个项集，使用项集与事务进行比较，计算每个项集的支持度计数。但是该方法的算法复杂度很高：O(NMw)。<br>改进方法：</p>
<blockquote>
<p>1、减少候选项的数目。先验原理，不计算支持度而删除某些候选项集。<br>2、减少比较次数。更高级的数据结构。</p>
</blockquote>
<h5 id="先验原理"><a href="#先验原理" class="headerlink" title="先验原理"></a>先验原理</h5><blockquote>
<p>先验原理：如果一个项集是频繁的，则它的所有子集也一定是频繁的。<br>相反的，如果一个项集是非频繁的，则它的所有超集也一定是非频繁的。<br>支持度计数的反单调性：一个项集的支持度不会超过它的子集的支持度。</p>
</blockquote>
<h5 id="（四）Apriori-算法的频繁项集产生"><a href="#（四）Apriori-算法的频繁项集产生" class="headerlink" title="（四）Apriori 算法的频繁项集产生"></a>（四）Apriori 算法的频繁项集产生</h5><p>过程图：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-d801677ed00d5e34.png" alt="6_03.png"></p>
<p>算法的流程：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-b2707e258f78bc77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_04.png"></p>
<p>算法讲解：<br>1、先定一个阈值k。<br>2、候选项集为1-项集的，计算支持度，若支持度大于阈值，则保留；若小于则剔除。<br>3、使用(k-1)-项集，产生k-项集。<br>4、重复上面的步骤，直到无候选集（频繁集），结束。</p>
<h5 id="1、Apriori-算法："><a href="#1、Apriori-算法：" class="headerlink" title="1、Apriori 算法："></a>1、Apriori 算法：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">k = 1</div><div class="line">F_(1) = &#123;1-项集 &gt;= min_c&#125;</div><div class="line">while true</div><div class="line">	k = k + 1</div><div class="line">	Ck = apriori_gen(F_(k-1)) \\产生候选集</div><div class="line">	for c in Ck do \\事务</div><div class="line">		for t in T do</div><div class="line">			if isin(t,c)</div><div class="line">			dc = dc + 1 \\支持度计数</div><div class="line">	F_(k) = &#123;提取频繁k-项集^dc &gt;= min_c&#125;</div></pre></td></tr></table></figure>
<h5 id="2、Apriori-gen方法："><a href="#2、Apriori-gen方法：" class="headerlink" title="2、Apriori_gen方法："></a>2、Apriori_gen方法：</h5><h6 id="F-k-1-F-1-方法"><a href="#F-k-1-F-1-方法" class="headerlink" title="F(k-1)*F(1)方法"></a>F(k-1)*F(1)方法</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-5b2cddb67e3135c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_05.png"></p>
<h6 id="F-k-1-F-k-1-方法"><a href="#F-k-1-F-k-1-方法" class="headerlink" title="F(k-1)*F(k-1)方法"></a>F(k-1)*F(k-1)方法</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-0c5e063896248cfc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_06.png"></p>
<p>原理：使用了字典序，例如：算法不会合并{啤酒，尿布}{尿布，牛奶}，因为如果{啤酒，尿布，牛奶}有效，则它应该由{啤酒，尿布}{啤酒，牛奶}合并。</p>
<h5 id="支持度计数"><a href="#支持度计数" class="headerlink" title="支持度计数"></a>支持度计数</h5><p>支持度计数在apriori_gen函数的候选项保留下来的之中计算。<br>一种枚举方法是：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-aaf218ec8469cee6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_07.png"></p>
<p>每项都以字典序排列，按照上面的枚举。</p>
<h6 id="使用hash树进行支持度计数"><a href="#使用hash树进行支持度计数" class="headerlink" title="使用hash树进行支持度计数"></a>使用hash树进行支持度计数</h6><p>[略]</p>
<h5 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a>计算复杂度</h5><p>[略]</p>
<h3 id="二、规则产生"><a href="#二、规则产生" class="headerlink" title="二、规则产生"></a>二、规则产生</h3><h4 id="（1）基于置信度的剪枝"><a href="#（1）基于置信度的剪枝" class="headerlink" title="（1）基于置信度的剪枝"></a>（1）基于置信度的剪枝</h4><h5 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h5><blockquote>
<p>如果 X-&gt;Y-X 不满足置信度阈值，则X’-&gt;Y-X’ 的规则一定不满足置信度阈值，其中，X’ 是 X 的子集。</p>
</blockquote>
<h4 id="（2）Apriori-规则产生"><a href="#（2）Apriori-规则产生" class="headerlink" title="（2）Apriori 规则产生"></a>（2）Apriori 规则产生</h4><p>可以利用上面的定理进行剪枝，如左边的bcd-&gt;a不满足置信度阈值，则下面的都减去：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-65f6188c6b9efd01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_08.png"></p>
<h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-3bc842139c766c37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_09.png"></p>
<h3 id="三、频繁项集的紧凑表示"><a href="#三、频繁项集的紧凑表示" class="headerlink" title="三、频繁项集的紧凑表示"></a>三、频繁项集的紧凑表示</h3><h4 id="（1）极大频繁项集"><a href="#（1）极大频繁项集" class="headerlink" title="（1）极大频繁项集"></a>（1）极大频繁项集</h4><blockquote>
<p>极大频繁项集（maximal frequent itemset）：它的直接超集都不是频繁的，频繁项集。</p>
</blockquote>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-ed019fe46e334ffd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_10.png"></p>
<p>如上图，{ad}、{ace}、{bcde} 均是极大频繁项集。</p>
<h4 id="（2）闭频繁项集"><a href="#（2）闭频繁项集" class="headerlink" title="（2）闭频繁项集"></a>（2）闭频繁项集</h4><blockquote>
<p>闭项集（closed itemset）：项集X是闭的，如果它的直接超集都不具有和它相同的支持度计数。</p>
</blockquote>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-0b68705bb8cc5be1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_11.png"></p>
<p>如上图，{b}{ad}都不是闭项集，而{bc}是闭项集。</p>
<blockquote>
<p>闭频繁项集（closed frequent itemset）一个项集是闭频繁项集，它是闭的，并且它的支持度计数大于或等于最小支持度阈值。</p>
</blockquote>
<p>计算闭频繁项集的支持度算法：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-32bbf860fa045aa0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_12.png"></p>
<p>项集之间的关系：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-e0c5f5413c6a7afa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_13.png"></p>
<h3 id="四、产生频繁项集的其他方法"><a href="#四、产生频繁项集的其他方法" class="headerlink" title="四、产生频繁项集的其他方法"></a>四、产生频繁项集的其他方法</h3><p>[略]</p>
<h3 id="五、FP增长算法"><a href="#五、FP增长算法" class="headerlink" title="五、FP增长算法"></a>五、FP增长算法</h3><p>[略]</p>
<h3 id="六、关联模式的评估"><a href="#六、关联模式的评估" class="headerlink" title="六、关联模式的评估"></a>六、关联模式的评估</h3><h4 id="（1）兴趣度的客观度量"><a href="#（1）兴趣度的客观度量" class="headerlink" title="（1）兴趣度的客观度量"></a>（1）兴趣度的客观度量</h4><h5 id="支持度-置信度框架的局限性"><a href="#支持度-置信度框架的局限性" class="headerlink" title="支持度-置信度框架的局限性"></a>支持度-置信度框架的局限性</h5><p>[略]</p>
<h5 id="兴趣因子"><a href="#兴趣因子" class="headerlink" title="兴趣因子"></a>兴趣因子</h5><p>[略]</p>
<h5 id="相关分析"><a href="#相关分析" class="headerlink" title="相关分析"></a>相关分析</h5><p>[略]</p>
<h5 id="IS度量"><a href="#IS度量" class="headerlink" title="IS度量"></a>IS度量</h5><p>[略]</p>
<h5 id="1、其他客观度量"><a href="#1、其他客观度量" class="headerlink" title="1、其他客观度量"></a>1、其他客观度量</h5><p>度量分为对称和非对称：</p>
<blockquote>
<p>对称：M(A-&gt;B)=M(B-&gt;A)。用于评价项集。<br>非对称：M(A-&gt;B)!=M(B-&gt;A)。用于分析关联规则。</p>
</blockquote>
<p>对称度量：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-8f3593ce3505ae32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_14.png"></p>
<p>非对称度量：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-7432adb9a6ea16a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_15.png"></p>
<h5 id="2、客观度量的一致性"><a href="#2、客观度量的一致性" class="headerlink" title="2、客观度量的一致性"></a>2、客观度量的一致性</h5><p>上面提到的一系列的度量，不一定都是一致的，需要具体分析。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-a2192e8898d5c392.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6_16.png"></p>
<h5 id="3、客观度量的性质"><a href="#3、客观度量的性质" class="headerlink" title="3、客观度量的性质"></a>3、客观度量的性质</h5><p>[略]<br>[后略]</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、基本概念&quot;&gt;&lt;a href=&quot;#一、基本概念&quot; class=&quot;headerlink&quot; title=&quot;一、基本概念&quot;&gt;&lt;/a&gt;一、基本概念&lt;/h3&gt;&lt;h5 id=&quot;（一）基本概念&quot;&gt;&lt;a href=&quot;#（一）基本概念&quot; class=&quot;headerlink&quot; title=&quot;（一）基本概念&quot;&gt;&lt;/a&gt;（一）基本概念&lt;/h5&gt;&lt;h6 id=&quot;二元概念&quot;&gt;&lt;a href=&quot;#二元概念&quot; class=&quot;headerlink&quot; title=&quot;二元概念&quot;&gt;&lt;/a&gt;二元概念&lt;/h6&gt;&lt;p&gt;对于购物篮数据，使用二元变量表示。1表示购买，0表示没有购买。&lt;/p&gt;
&lt;h6 id=&quot;项集和支持度计数&quot;&gt;&lt;a href=&quot;#项集和支持度计数&quot; class=&quot;headerlink&quot; title=&quot;项集和支持度计数&quot;&gt;&lt;/a&gt;项集和支持度计数&lt;/h6&gt;&lt;p&gt;事务：一行数据。&lt;br&gt;k-项集：一个事务中，出现项。如：3-项集，{啤酒，尿布，牛奶}&lt;br&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/3341358-11295870eaafecad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;6_01.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;支持度计数：&lt;br&gt;$$\sigma (X)=|\left \{ t_{i}|X\subseteq t_{i},t_{i}\in T \right \}|$$&lt;/p&gt;
&lt;p&gt;如，上式中，项集{啤酒，尿布，牛奶}的支持度计数为2，因为只有2个事务同时包含3个项。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
      <category term="关联分析" scheme="http://yoursite.com/tags/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>分类（6）：不平衡和多分类问题</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_classfy_06/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_classfy_06/</id>
    <published>2017-02-15T13:37:36.000Z</published>
    <updated>2017-02-15T13:53:25.606Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、不平衡问题"><a href="#一、不平衡问题" class="headerlink" title="一、不平衡问题"></a>一、不平衡问题</h4><h5 id="（1）不平衡数据"><a href="#（1）不平衡数据" class="headerlink" title="（1）不平衡数据"></a>（1）不平衡数据</h5><p>例如：一个产品生产的不合格产品数量会远低于合格产品数量。信用卡欺诈的检测中，合法交易远远多于欺诈交易。<br>这时候，准确率的度量会出现一些问题，因为她把每个类都看得同等重要。<br>例如，1%的信用卡交易是欺诈行为，则预测每个交易都是合法的模型有99%的准确率，它也可能检测不到任何欺诈交易。</p>
<h5 id="（2）混淆矩阵"><a href="#（2）混淆矩阵" class="headerlink" title="（2）混淆矩阵"></a>（2）混淆矩阵</h5><p>在不平衡数据中，稀有类比较有意义，对于二元分类，稀有类通常记为正类，而多数类被认为是负类。下面显示了混淆矩阵：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-77c3b86f48870b96.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_37.png"></p>
<a id="more"></a>
<blockquote>
<p>真正（true positive，TP）：++<br>假正（false positive，FP）：-+<br>真负（true negative，TN）：–<br>假负（false negative，FN）：+-</p>
</blockquote>
<p>真正率（true positive rate，TPR）或灵敏度（sensitivity）：<br>$$ TPR=\frac{TP}{TP+FN}=\frac{(++)}{(++)+(+-)}$$<br>真负率（true negative rate，TNR）或特指度（specificity）：<br>$$TNR=\frac{TN}{TN+FP}=\frac{(–)}{(–)+(-+)}$$<br>假正率（false positive rate，FPR）：<br>$$FPR=\frac{FP}{TN+FP}=\frac{(+-)}{(–)+(-+)}$$<br>假负率（false negative rate，FNR）：<br>$$ FNR=\frac{FN}{FN+TP}=\frac{(-+)}{(-+)+(++)}$$<br>精度（precision）：<br>$$ p=\frac{TP}{TP+FP}=\frac{(++)}{(++)+(-+)}$$<br>召回率（recall）即为真正率：<br>$$r=\frac{(TP)}{(TP)+(FN)}=\frac{(++)}{(++)+(+-)}$$<br>精度和召回率是很重要的度量量，称为 F1 统计量：<br>$$ F_{1}=\frac{2rp}{r+p}=\frac{2\times TP}{2\times TP+FP+FN}=\frac{2}{\frac{1}{r}+\frac{1}{p}}$$<br>F1 是召回率和精度的调和平均数，F1 趋近于它们之间的较小值，因此，一个高的 F1 确保精度和召回率都高。<br>Fb 的公式：<br>$$ F_{b}=\frac{(b^{2}+1)rp}{r+b^{2}p}=\frac{(b^{2}+1)}{\frac{1}{r}+\frac{b^{2}}{p}}$$<br>低的 b 使得 Fb 更加接近精度，高的 b 使得 Fb 更加接近召回率。</p>
<h5 id="（3）接受者操作曲线（ROC）"><a href="#（3）接受者操作曲线（ROC）" class="headerlink" title="（3）接受者操作曲线（ROC）"></a>（3）接受者操作曲线（ROC）</h5><blockquote>
<p>是真正率和假正率取折中的一种图形化方法。真正率为 y 轴，假正率为 x 轴。</p>
</blockquote>
<p>ROC的几个关键点：</p>
<blockquote>
<p>（TPR=0,FPR=0）:把所有的都预测为负<br>（TPR=1,FPR=1）:把所有的都预测为正<br>（TPR=1,FPR=0）:理想模型。只要是正的，都预测为正。</p>
</blockquote>
<p>一个好的分类器，尽量靠近左上角，随机猜想为对角线。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-291214111746c1d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_38.png"></p>
<p>产生ROC曲线方法：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-785ee8715b8e3937.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_39.png"></p>
<h5 id="（4）代价敏感学习"><a href="#（4）代价敏感学习" class="headerlink" title="（4）代价敏感学习"></a>（4）代价敏感学习</h5><p>模型 M 的代价：<br>$$ C_{t}(M)=TP\times C(+,+)+FP\times C(-,+)+FN\times C(+,1)+FN\times C(-,-)$$</p>
<p>如下是一个代价矩阵：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-297e0b3d8f363ce1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_40.png"></p>
<p>它可以把决策边界扩展：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-e36c99b877fc8be2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_41.png"></p>
<p>对于代价矩阵，若 C(+,+)=C(-,-)=0 的情况，分类正确不需要代价，则：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-359569c4900501fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_42.png"></p>
<p>求解可以得到决策边界。</p>
<h6 id="基于抽样方法"><a href="#基于抽样方法" class="headerlink" title="基于抽样方法"></a>基于抽样方法</h6><p>对于样本进行处理，假设有100个正样本和1000个负样本。<br>不充分抽样（udersampling）：取和正样本一样数量的负样本，取100个负样本，形成训练集。<br>过分抽样（oversampling）：将正样本复制，或者重复抽样，使得正样本的数量和负样本一样1000个。</p>
<h4 id="二、多类问题"><a href="#二、多类问题" class="headerlink" title="二、多类问题"></a>二、多类问题</h4><blockquote>
<p>1、one-vs-rest 方法。将多类问题分解为 K 个二类问题，将属于$y_{i}$的归为正类，而其他类被分为负类，依次进行。<br>2、one-vs-one 方法。它构建$\frac{K(K-1)}{2}$ 个二分类器，每一个分类器用来区分一对类 $(y_{i},y_{j})$ ，当为类 $(y_{i},y_{j})$ 建立分类器的时候，将不属于 $(y_{i},y_{j})$ 的样本忽略掉。</p>
</blockquote>
<p>例子：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-8712856c5236b70b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_43.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-bb9f20a6e31754da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_44.png"></p>
<p>使用上述两种方法建模后，可能出现分类平局。另一种方法，将输出转变为概率估计，将实例给予高概率的类。</p>
<h5 id="纠错输出编码"><a href="#纠错输出编码" class="headerlink" title="纠错输出编码"></a>纠错输出编码</h5><p>纠错输出编码（error-correcting output coding，ECOC）：一种处理多分类更加鲁棒的方法，给予每个类一个代码字，对于每个可能预测错误的，选取距离代码字最近的那一类。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、不平衡问题&quot;&gt;&lt;a href=&quot;#一、不平衡问题&quot; class=&quot;headerlink&quot; title=&quot;一、不平衡问题&quot;&gt;&lt;/a&gt;一、不平衡问题&lt;/h4&gt;&lt;h5 id=&quot;（1）不平衡数据&quot;&gt;&lt;a href=&quot;#（1）不平衡数据&quot; class=&quot;headerlink&quot; title=&quot;（1）不平衡数据&quot;&gt;&lt;/a&gt;（1）不平衡数据&lt;/h5&gt;&lt;p&gt;例如：一个产品生产的不合格产品数量会远低于合格产品数量。信用卡欺诈的检测中，合法交易远远多于欺诈交易。&lt;br&gt;这时候，准确率的度量会出现一些问题，因为她把每个类都看得同等重要。&lt;br&gt;例如，1%的信用卡交易是欺诈行为，则预测每个交易都是合法的模型有99%的准确率，它也可能检测不到任何欺诈交易。&lt;/p&gt;
&lt;h5 id=&quot;（2）混淆矩阵&quot;&gt;&lt;a href=&quot;#（2）混淆矩阵&quot; class=&quot;headerlink&quot; title=&quot;（2）混淆矩阵&quot;&gt;&lt;/a&gt;（2）混淆矩阵&lt;/h5&gt;&lt;p&gt;在不平衡数据中，稀有类比较有意义，对于二元分类，稀有类通常记为正类，而多数类被认为是负类。下面显示了混淆矩阵：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/3341358-77c3b86f48870b96.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;5_37.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="分类算法" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>分类（5）：组合分类器-随机森林</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_classfy_05/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_classfy_05/</id>
    <published>2017-02-15T13:32:47.000Z</published>
    <updated>2017-02-15T13:53:47.019Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、组合方法"><a href="#一、组合方法" class="headerlink" title="一、组合方法"></a>一、组合方法</h4><h5 id="（1）组合分类器原理："><a href="#（1）组合分类器原理：" class="headerlink" title="（1）组合分类器原理："></a>（1）组合分类器原理：</h5><p>考虑25个二元分类器，每一个分类误差a=0.35。组合分类器通过多数投票，如果基分类器是独立的，则仅当超过一半的基分类器都预测错误时，组合才会错误，则：<br>$$ e_{ensemble}=\sum_{i=1}^{25}C_{25}^{i}a^{i}(1-a)^{25-i}=0.06$$</p>
<p>可以看出，其远低于0.35。</p>
<h5 id="（2）组合分类器与基分类器比较："><a href="#（2）组合分类器与基分类器比较：" class="headerlink" title="（2）组合分类器与基分类器比较："></a>（2）组合分类器与基分类器比较：</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-54f2009701fddbac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_26.png"></p>
<a id="more"></a>
<p>上图，虚线表示所有基分类器都一样，实线表示所有基分类器都独立。可以看出，当基分类器的错误率大于0.5（仅这个例子吗？）时候，组合分类器的性能不比基分类器的性能好。<br>组合分类器的性能优于基分类器的条件：</p>
<blockquote>
<p>1、基分类器应该是<strong>独立</strong>的。<br>2、基分类器应当好于随机猜想。</p>
</blockquote>
<h5 id="（3）袋装（bagging）-自助法（bootstrap-aggregating）"><a href="#（3）袋装（bagging）-自助法（bootstrap-aggregating）" class="headerlink" title="（3）袋装（bagging）-自助法（bootstrap aggregating）"></a>（3）袋装（bagging）-自助法（bootstrap aggregating）</h5><h6 id="袋装-自助法（bootstrap）："><a href="#袋装-自助法（bootstrap）：" class="headerlink" title="袋装-自助法（bootstrap）："></a>袋装-自助法（bootstrap）：</h6><p>训练集是对于原数据集的有放回抽样，如果原始数据集N，可以证明，大小为N的自助样本大约包含原数据63.2%的记录。当N充分大的时候，1-（1-1/N）^(N) 概率逼近 1-e^(-1)=0.632。抽样 b 次，产生 b 个bootstrap样本，则，总准确率为（accs为包含所有样本计算的准确率）：<br>$$  acc_{boot}=\frac{1}{b}\sum_{i=1}^{b}(0.632\times\varepsilon _{i}+0.368\times acc_{s})$$</p>
<h6 id="袋装算法："><a href="#袋装算法：" class="headerlink" title="袋装算法："></a>袋装算法：</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">设 k 为自助样本的数目</div><div class="line"><span class="keyword">for</span> i = <span class="number">1</span> to k do</div><div class="line">  生成一个大小为 N 的自助样本 Dt</div><div class="line">  在自助样本 Dt 上训练一个基分类器 Ci</div><div class="line">C*=argmax（Ci...）</div></pre></td></tr></table></figure>
<h6 id="袋装举例理解："><a href="#袋装举例理解：" class="headerlink" title="袋装举例理解："></a>袋装举例理解：</h6><p>下面的这个数据集，使用决策树，熵值来分裂，可以得到分裂点为：x&lt;=0.35  或 x&lt;=0.75，但是无论是哪个分类点，准确率都最多为70%。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-ac32116bd2c12d57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_27.png"></p>
<p>使用袋装抽样：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-567a1833f3ab1c6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_28.png"></p>
<p>使用简单的求和，取符号，可以发现，分类正确率为100%：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-d07e2f579ee5f696.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_29.png"></p>
<h6 id="袋装评价："><a href="#袋装评价：" class="headerlink" title="袋装评价："></a>袋装评价：</h6><blockquote>
<p>1、通过降低基分类器的<strong>方差</strong>改善了泛化误差<br>2、袋装的性能依赖于基分类器的稳定性。如果基分类器是不稳定的，袋装有助于降低训练数据的随机波动导致的误差；如果基分类器是稳定的，则组合分类器的误差主要由基分类器的偏倚引起，则这种情况下，袋装可能会降低分类器的性能。<br>3、袋装中的数据是均概率被选中，所以对特定数据不敏感，对于噪音，不太受过拟合影响。</p>
</blockquote>
<h5 id="（4）提升（Boosting）"><a href="#（4）提升（Boosting）" class="headerlink" title="（4）提升（Boosting）"></a>（4）提升（Boosting）</h5><blockquote>
<p>提升是一个迭代过程，自适应的改变样本的分布，使得基分类器聚焦在那些很难分类的样本上，提升每次给一个训练样本一个权值，在每一轮结束的时候自动地调整权值。</p>
</blockquote>
<p>现在又很多提升算法，算法的差别在于：</p>
<blockquote>
<p>（1）每轮提升结束时如何更新训练样本权值<br>（2）如何组合每个分类器的预测</p>
</blockquote>
<h6 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h6><p>在该算法中，基分类器 Ci 的重要性依赖于它的错误率，错误率的定义：<br>$$ error_{i}=\frac{1}{N}\left[\sum_{j=1}^{N}w_{j}I(C_{i}(x_{j}\neq y_{j}))\right]$$<br>对于I，为指示变量，错误个数的加权取平均，基分类器的重要度 \alpha 为：<br>$$ \alpha_{i}=\frac{1}{2}ln\left(\frac{1-error_{i}}{error_{i}}\right)$$<br>作出重要度 \alpha 关于 error 的图：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-f9aa54c012a54386.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_30.png"></p>
<p>发现错误率接近 0 时候，重要度很大，接近 1 时候，重要度负向很大。<br>Adaboost 的权值更新有以下给出，第 j 次迭代：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-248390a2b40241cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_31.png"></p>
<p>Zj 是一个正规因子，用于确保：<br>$$\sum_{i}w_{i}^{j+1}=1$$</p>
<h6 id="AdaBoost算法："><a href="#AdaBoost算法：" class="headerlink" title="AdaBoost算法："></a>AdaBoost算法：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-eac202ad78997335.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_32.png"></p>
<h6 id="AdaBoost例子："><a href="#AdaBoost例子：" class="headerlink" title="AdaBoost例子："></a>AdaBoost例子：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-1d3ea4e0010c0305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_33.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-d5ce991ea50f4bd3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_34.png"></p>
<blockquote>
<p>1、该组合分类器的训练误差呈指数递减，从而算法很快就会收敛。<br>2、但是它倾向于那些被误分类的样本，所以提升技术很容易受到过拟合的影响。</p>
</blockquote>
<h4 id="二、随机森林（Random-Forest）"><a href="#二、随机森林（Random-Forest）" class="headerlink" title="二、随机森林（Random Forest）"></a>二、随机森林（Random Forest）</h4><h5 id="随机森林的过程图："><a href="#随机森林的过程图：" class="headerlink" title="随机森林的过程图："></a>随机森林的过程图：</h5><p><img src="http://upload-images.jianshu.io/upload_images/3341358-c5fc2f3eb53f229b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_35.png"></p>
<p>已经从理论上证明了，当树的数目足够大的时候，随机森林的泛化误差的上界收敛于下面表达式：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-7f6c9671e2e85e76.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_36.png"></p>
<h5 id="随机森林性质"><a href="#随机森林性质" class="headerlink" title="随机森林性质"></a>随机森林性质</h5><p>每棵决策树都使用一个从固定概率分布产生的随机向量。可以使用多种方法将随机向量合并到树中。</p>
<h6 id="不同的随机森立方法："><a href="#不同的随机森立方法：" class="headerlink" title="不同的随机森立方法："></a>不同的随机森立方法：</h6><blockquote>
<p>1、Forest-RI。随机选择 F 个输入特征来对决策树的结点进行分裂，树之后完全增长不进行任何修剪，这有助于减少树的偏倚。之后用多数投票表决来组合预测。为了增加随机性，可以使用自助样本。<br>2、Forest-RC。d 的数目太小的情况，需要增大特征空间，创建输入特征的线性组合。输入特征用区间[-1,1]的均匀分布产生的系数进行线性组合。<br>3、对于每个结点，从 F 个最佳划分中随机选择一个，该方法也是比上面两个更花费时间。<br>4、随机森林的分裂准确率与Adaboost相媲美，但它对噪声更加鲁棒，运行速度也比Adaboost快得多。</p>
</blockquote>
<h6 id="随机森林的一些参数选择"><a href="#随机森林的一些参数选择" class="headerlink" title="随机森林的一些参数选择"></a>随机森林的一些参数选择</h6><p>通常选取特征数目为：<br>$$ F=log_{2}^{d}+1$$<br>d 为输入特征数。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、组合方法&quot;&gt;&lt;a href=&quot;#一、组合方法&quot; class=&quot;headerlink&quot; title=&quot;一、组合方法&quot;&gt;&lt;/a&gt;一、组合方法&lt;/h4&gt;&lt;h5 id=&quot;（1）组合分类器原理：&quot;&gt;&lt;a href=&quot;#（1）组合分类器原理：&quot; class=&quot;headerlink&quot; title=&quot;（1）组合分类器原理：&quot;&gt;&lt;/a&gt;（1）组合分类器原理：&lt;/h5&gt;&lt;p&gt;考虑25个二元分类器，每一个分类误差a=0.35。组合分类器通过多数投票，如果基分类器是独立的，则仅当超过一半的基分类器都预测错误时，组合才会错误，则：&lt;br&gt;$$ e_{ensemble}=\sum_{i=1}^{25}C_{25}^{i}a^{i}(1-a)^{25-i}=0.06$$&lt;/p&gt;
&lt;p&gt;可以看出，其远低于0.35。&lt;/p&gt;
&lt;h5 id=&quot;（2）组合分类器与基分类器比较：&quot;&gt;&lt;a href=&quot;#（2）组合分类器与基分类器比较：&quot; class=&quot;headerlink&quot; title=&quot;（2）组合分类器与基分类器比较：&quot;&gt;&lt;/a&gt;（2）组合分类器与基分类器比较：&lt;/h5&gt;&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/3341358-54f2009701fddbac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;5_26.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="分类算法" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>分类（4）：支持向量机（SVM）</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_classfy_04/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_classfy_04/</id>
    <published>2017-02-15T13:26:40.000Z</published>
    <updated>2017-02-15T13:53:43.243Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h4><p>SVM 寻找一个最大边缘超平面（maximal margin hyperplane），使得将数据分开，并且有最大的margin，泛化能力。</p>
<h5 id="（1）结构风险最小化（structual-risk-minimization，SRM）"><a href="#（1）结构风险最小化（structual-risk-minimization，SRM）" class="headerlink" title="（1）结构风险最小化（structual risk minimization，SRM）"></a>（1）结构风险最小化（structual risk minimization，SRM）</h5><p>线性分类器的边缘与泛化误差之间的关系，分类器的泛化误差在最坏的情况下：<br>$$R\leqslant R_{e}+\varphi \left(\frac{h}{N},\frac{log(\eta )}{N}\right)$$<br>$\varphi$是h的单调增函数，$1-\eta$表示概率。<br><a id="more"></a></p>
<h5 id="（2）SVM线性分类器"><a href="#（2）SVM线性分类器" class="headerlink" title="（2）SVM线性分类器"></a>（2）SVM线性分类器</h5><p>模型：<br>$$ w\cdot x+b=0$$<br>线性分类图：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-aaf039d936a7738e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_10.png"><br>于是我们有：<br>$$ w\cdot x_{s}+b=k,w\cdot x_{c}+b=k$$<br>其中，k&gt;0，左边表示在决策边界的上面。k’&lt;0，右边表示在决策边界下面。<br>如果我们标记一个类为+1，另一个类为-1，则有：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-3b3c4a5c74c6e299.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_11.png"></p>
<p>距离：<br>$$ w(x_{1}-x_{2})=2\rightarrow d=\frac{2}{\left | w \right |},\left | w \right |=\sqrt{w_{1}^{2}+w_{2}^{2}+…+w_{k}^{2}}$$</p>
<h5 id="（3）线性SVM：可分情况"><a href="#（3）线性SVM：可分情况" class="headerlink" title="（3）线性SVM：可分情况"></a>（3）线性SVM：可分情况</h5><h6 id="决策边界的参数"><a href="#决策边界的参数" class="headerlink" title="决策边界的参数"></a>决策边界的参数</h6><p>上面的为+1，下面的为-1，则可以概括为：<br>$$ y_{i}(w\cdot x_{i}+b)\geqslant 1,i=1,2,…,N$$<br>最大化边缘，等价于最小化下面目标函数：<br>$$f(w)=\frac{\left|w\right|^{2}}{2}$$<br>目标函数是二次的，约束在w、b上是线性的，这是一个凸优化问题，通过拉格朗日乘子求解。<br>$$L_{p}=\frac{1}{2}\left|w\right|^{2}-\sum_{i=1}^{N}\lambda _{i}(y_{i}\left(w\cdot x_{i}+b)-1\right)$$</p>
<h6 id="Karuch-Kuhn-Tucher（KKT）："><a href="#Karuch-Kuhn-Tucher（KKT）：" class="headerlink" title="Karuch-Kuhn-Tucher（KKT）："></a>Karuch-Kuhn-Tucher（KKT）：</h6><p>把不等式约束转换为等式约束，限制拉格朗日乘子非负。<br>$$ \lambda_{i}\geqslant 1$$<br>$$ \lambda_{i}[y_{i}(w\cdot x_{i}+b)-1]=0$$<br>下面的等式，使得许多拉格朗日乘子都变为零。该约束表明，除非$y_{i}(w*x_{i}+b)=1$，否则拉格朗日乘子必须为零。<br>那些$\lambda&gt;0$的训练实例在两个超平面上，称为支持向量，$lambda=0$的肯定不在超平面上。决策边界w、b仅仅依赖这些支持向量。<br>此外，也可以使用对偶拉格朗日，使用二次规划求解。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-71585de3f64cfe25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_12.png"></p>
<h6 id="SVM的例子："><a href="#SVM的例子：" class="headerlink" title="SVM的例子："></a>SVM的例子：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-271cf98ca192603c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_13.png"></p>
<p>&lt;简书&gt;：我的心在滴血啊，写了一下午，你居然没有保存，网站页面设计的“保存中…”“已保存”就是个普通js吗？没有事务的吗？就修改文档的时候触发一下，然后也不判断是否联网，是否保存等。逗！！再不用简书。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、基本概念&quot;&gt;&lt;a href=&quot;#一、基本概念&quot; class=&quot;headerlink&quot; title=&quot;一、基本概念&quot;&gt;&lt;/a&gt;一、基本概念&lt;/h4&gt;&lt;p&gt;SVM 寻找一个最大边缘超平面（maximal margin hyperplane），使得将数据分开，并且有最大的margin，泛化能力。&lt;/p&gt;
&lt;h5 id=&quot;（1）结构风险最小化（structual-risk-minimization，SRM）&quot;&gt;&lt;a href=&quot;#（1）结构风险最小化（structual-risk-minimization，SRM）&quot; class=&quot;headerlink&quot; title=&quot;（1）结构风险最小化（structual risk minimization，SRM）&quot;&gt;&lt;/a&gt;（1）结构风险最小化（structual risk minimization，SRM）&lt;/h5&gt;&lt;p&gt;线性分类器的边缘与泛化误差之间的关系，分类器的泛化误差在最坏的情况下：&lt;br&gt;$$R\leqslant R_{e}+\varphi \left(\frac{h}{N},\frac{log(\eta )}{N}\right)$$&lt;br&gt;$\varphi$是h的单调增函数，$1-\eta$表示概率。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="分类算法" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>分类（3）：人工神经网络（ANN）</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_classfy_03/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_classfy_03/</id>
    <published>2017-02-15T13:23:21.000Z</published>
    <updated>2017-02-15T13:53:40.450Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、感知器"><a href="#一、感知器" class="headerlink" title="一、感知器"></a>一、感知器</h4><p>下图为一个感知器，单个神经元。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-c8d5e57205a85f05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_06.png"><br>该感知器的算法：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-3578cedeed16cbe4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_07.png"><br><a id="more"></a></p>
<h4 id="二、多层人工神经网络"><a href="#二、多层人工神经网络" class="headerlink" title="二、多层人工神经网络"></a>二、多层人工神经网络</h4><h5 id="（1）基本概念"><a href="#（1）基本概念" class="headerlink" title="（1）基本概念"></a>（1）基本概念</h5><p>神经网络，这里先以前馈神经网络为介绍，每层为全连接，则对于2个神经元，参数为：</p>
<blockquote>
<p>（1）w权值，（2）b偏置，（3）delta 激活函数。</p>
</blockquote>
<p>多层神经网络的结构图，以下为前馈神经网络的结构（2层）：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-cd4ad3a0be5116c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_08.png"><br>常用的 delta 激活函数：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-234d1970a2ebc9ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_09.png"><br>基于梯度下降的权值更新：<br>$$ w_{j}\leftarrow w_{j}-\lambda \frac{\partial E(w)}{\partial w_{j}}$$<br>$\lambda$为学习率。</p>
<h5 id="（2）反向传播（back-propagation）"><a href="#（2）反向传播（back-propagation）" class="headerlink" title="（2）反向传播（back-propagation）"></a>（2）反向传播（back-propagation）</h5><p>对于数据集，可以使用mini-batch，每次选取一部分，直到将数据使用完毕。每次每个数据包括两个阶段， 向前阶段和向后阶段。</p>
<blockquote>
<p>向前阶段：通过初始权值、初始偏置和激活函数，每次更新隐藏层和输出层的值；<br>向后阶段：通过权值更新法则，更新权值和偏置。<br>直到数据使用完毕，或者，权值更新的差值小于某个阈值。</p>
</blockquote>
<h5 id="（3）神经网络特点"><a href="#（3）神经网络特点" class="headerlink" title="（3）神经网络特点"></a>（3）神经网络特点</h5><blockquote>
<p>1、至少含有一个隐藏层的是一种普适近似（universal approximator），即可以用来近似任何目标函数。<br>2、可以处理冗余特征，冗余特征的权值会非常小。<br>3、梯度下降法会收敛到局部极小值，避免方法可以在权值更新公式上加上一个动量项（momentum term）</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、感知器&quot;&gt;&lt;a href=&quot;#一、感知器&quot; class=&quot;headerlink&quot; title=&quot;一、感知器&quot;&gt;&lt;/a&gt;一、感知器&lt;/h4&gt;&lt;p&gt;下图为一个感知器，单个神经元。&lt;br&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/3341358-c8d5e57205a85f05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;5_06.png&quot;&gt;&lt;br&gt;该感知器的算法：&lt;br&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/3341358-3578cedeed16cbe4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;5_07.png&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="分类算法" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>分类（2）：k-最近邻、贝叶斯分类器</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_classfy_02/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_classfy_02/</id>
    <published>2017-02-15T13:14:31.000Z</published>
    <updated>2017-02-15T13:53:37.398Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、k-最近邻"><a href="#一、k-最近邻" class="headerlink" title="一、k-最近邻"></a>一、k-最近邻</h4><h5 id="1、算法"><a href="#1、算法" class="headerlink" title="1、算法"></a>1、算法</h5><p>积极学习方法（eager learner）：通过训练样本建立模型。<br>消极学习方法（lazy learner）：实例的学习，k-最近邻就属于这种。</p>
<h6 id="k-最近邻算法："><a href="#k-最近邻算法：" class="headerlink" title="k-最近邻算法："></a>k-最近邻算法：</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">令k是最近邻数目，D是训练样例集合</div><div class="line"><span class="keyword">for</span> z <span class="keyword">in</span> 样例集合:</div><div class="line">  计算 z 和每个样例 (x,y) 的距离 d</div><div class="line">  选择离 z 前 k 个近距离的点，为集合 Dt</div><div class="line">  z的标记 y 为 Dt 中类较多的</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>k-最近邻采用多数表决的方法，该算法对 k 敏感：<br>$$y’=argmax_{v}\sum_{(x_{i},y_{i})\in D_{t}} I(v=y_{i})$$<br>所以，需要降低 k 的影响，一种途径就是对距离的不同加权，如下，因为距离远的影响要弱一些，以距离平方的倒数为权值。<br>$$y’=argmax_{v}\sum_{(x_{i},y_{i})\in D_{t}}w_{i}\times I(v=y_{i}),w_{i}=\frac{1}{d(x’,x_{i})^{2}}$$</p>
<h5 id="2、最近邻分类器特征："><a href="#2、最近邻分类器特征：" class="headerlink" title="2、最近邻分类器特征："></a>2、最近邻分类器特征：</h5><blockquote>
<p>（1）实例的学习，不需要建模，但分类测试的开销很大。<br>（2）当k比较小的时候，对噪声非常敏感。<br>（3）可以生成任意决策边界。</p>
</blockquote>
<h4 id="二、贝叶斯分类器"><a href="#二、贝叶斯分类器" class="headerlink" title="二、贝叶斯分类器"></a>二、贝叶斯分类器</h4><h5 id="1、贝叶斯公式"><a href="#1、贝叶斯公式" class="headerlink" title="1、贝叶斯公式"></a>1、贝叶斯公式</h5><p>$$P(Y_{j}|X)=\frac{P(X|Y_{j})P(Y_{j})}{P(X)}=\frac{P(X|Y_{j})P(Y_{j})}{\sum_{i=1}^{n}P(X|Y_{i})P(Y_{i})}$$</p>
<h5 id="2、朴素贝叶斯"><a href="#2、朴素贝叶斯" class="headerlink" title="2、朴素贝叶斯"></a>2、朴素贝叶斯</h5><h6 id="（1）条件独立性："><a href="#（1）条件独立性：" class="headerlink" title="（1）条件独立性："></a>（1）条件独立性：</h6><p>给定 Z，X 条件独立于 Y:<br>$$P(X|Y,Z)=P(X|Z)$$<br>则有：<br>$$P(X,Y|Z)=\frac{P(Z,Y,X)}{P(Z)}=\frac{P(Z,Y,X)}{P(Y,Z)}\frac{P(Y,Z)}{P(Z)}=P(X|Y,Z)P(Y|Z)=P(X|Z)P(Y|Z)$$</p>
<h6 id="（2）朴素贝叶斯分类器："><a href="#（2）朴素贝叶斯分类器：" class="headerlink" title="（2）朴素贝叶斯分类器："></a>（2）朴素贝叶斯分类器：</h6><p>$$P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}=\frac{P(X_{1},…,X_{d})P(Y)}{P(X)}=\frac{P(Y)\prod_{i=1}^{d}P(X_{i}|Y)}{P(X)}$$</p>
<h6 id="（3）连续属性的条件概率："><a href="#（3）连续属性的条件概率：" class="headerlink" title="（3）连续属性的条件概率："></a>（3）连续属性的条件概率：</h6><p><1>把每个连续属性离散化，用相应的区间去替代原来的属性，但若某一个区间的样本数目过少，不容易做出可靠的估计。</1></p>
<p><2>可以假设连续变量服从正态分布，Xi的概率等于：<br>$$P(X_{i}=x_{i}|Y=y_{j})=\frac{1}{\sqrt{2\pi}\sigma_{ij}}e^{-\frac{(x_{i}-\mu_{ij})^{2}}{2\sigma_{ij}}}$$<br>其中 $\mu$ 用样本均值估计， $\sigma$ 用样本方差估计。</2></p>
<h6 id="（4）朴素贝叶斯举例："><a href="#（4）朴素贝叶斯举例：" class="headerlink" title="（4）朴素贝叶斯举例："></a>（4）朴素贝叶斯举例：</h6><p>拖欠贷款为 Y 变量。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-cd962d2b90b84337.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_01.png"><br>测试记录X=（有房=否，婚姻状况=已婚，年收入=120K），求后验概率P（No|X）、P（Yes|X）。<br>总的 Y 可以知道，P（Yes）=0.3，P（No）=0.7。则：</p>
<blockquote>
<p>P（X | No）=P（有房=否 | No）x P（婚姻状况=已婚 | No）x P（年收入=120K | No）=0.0024<br>P（X | Yes）= P（有房=否 | Yes）x P（婚姻状况=已婚 | Yes）x P（年收入=120K | Yes）=0</p>
</blockquote>
<p>因为P（No|X）&gt;P（Yes|X），所以该测试分类为No，不拖欠贷款。<br>上例中，P（婚姻状况=已婚 | Yes）=0，可能会出现极端现象，为了防止出现0，朴素贝叶斯没法正确分类，可以使用 m 估计（m-estimate）：<br>$$ P(x_{i}|y_{j})=\frac{n_{c}+mp}{n+m}$$<br>$n$ 为 $y_{i}$ 的实例总数，$n_{c}$ 为 $y_{i}$ 中 $x_{i}$ 的实例数目，p 是用户指定，m 为等价样本大小的参数。上面的计算：P（婚姻状况=已婚 | Yes）=(0+3 x 1/3)/(3+3)=1/6，而不是0。</p>
<h6 id="（4）朴素贝叶斯特征："><a href="#（4）朴素贝叶斯特征：" class="headerlink" title="（4）朴素贝叶斯特征："></a>（4）朴素贝叶斯特征：</h6><blockquote>
<p>对于噪声点，朴素贝叶斯是健壮的。也可以处理属性值遗漏问题。<br>无关属性，朴素贝叶斯是健壮的。对于相关属性，可能会降低分类性能。</p>
</blockquote>
<h5 id="3、贝叶斯置信网络（Bayesian-belief-networks，BBN）"><a href="#3、贝叶斯置信网络（Bayesian-belief-networks，BBN）" class="headerlink" title="3、贝叶斯置信网络（Bayesian belief networks，BBN）"></a>3、贝叶斯置信网络（Bayesian belief networks，BBN）</h5><h6 id="（1）模型表示："><a href="#（1）模型表示：" class="headerlink" title="（1）模型表示："></a>（1）模型表示：</h6><p>两个主要成分：</p>
<blockquote>
<p>一个有向无环图（DAG），表示变量之间的关系；<br>一个概率表，把各个结点和它的直接父节点关联起来。</p>
</blockquote>
<p>性质1：条件独立<br>贝叶斯网络中的一个结点，如果它的父母结点已知，则它条件独立于它的所有非后代结点。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-9e01f1fad2d71412.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_02.png"><br>如图（b），给定C，A 条件独立于 B 和 D。<br>除了网络拓扑结构要求的条件独立外，每个结点还关联一个概率表。</p>
<blockquote>
<p>（1）如果结点 X 没有父母结点，则表中只包含先验概率P(X);<br>（2）如果结点 X 只有一个父母结点 Y，则表中包含先验概率P(X | Y);<br>（3）如果结点 X 有多个父母结点{Y1，Y2…，Yk}，则表中只包含先验概率P(X|Y1，Y2…，Yk);</p>
</blockquote>
<p>下图是一个贝叶斯置信网络。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-f75caad2586c4f19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_03.png"></p>
<h6 id="（2）建立模型："><a href="#（2）建立模型：" class="headerlink" title="（2）建立模型："></a>（2）建立模型：</h6><p>贝叶斯网络拓扑结构的生成算法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">设T=（X1，X2，...Xd）表示变量的全序</div><div class="line"><span class="keyword">for</span> j=<span class="number">1</span> to d do</div><div class="line">  令 XTj 表示 T 中第 j 个次序最高的变量</div><div class="line">  令A（XTj）=&#123;XT1，XT2，...XTj<span class="number">-1</span>&#125; 表示排在 XTj 前面的变量的集合</div><div class="line">  从A（XTj）中去掉对 Xj 没有影响的变量（使用先验知识）</div><div class="line">  在 XTj 和 A（XTj） 中的剩余变量之间画弧</div></pre></td></tr></table></figure></p>
<p>考虑到图5_03，经过循环后，得到的如下概率：</p>
<blockquote>
<p>P（D | E）化简为 P（D）<br>P（HD | E,D）不能化简<br>P（Hb | E,D,HD）化简为 P（Hb | D）<br>P（CP | E,D,HD,Hb）化简为 P（CP | HD,Hb）<br>P（BP | E,D,HD,Hb,CP）化简为 P（BP | HD）</p>
</blockquote>
<p>上面的算法，保证了不会生成环。<br>不同的变量排序会产生不同的拓扑结构，理论上需要 d！种排序才能找到最优的，开销很大。代替方法是把变量分成原因变量和结果变量，从原因到结果画弧。</p>
<h6 id="（3）使用BNN进行推理："><a href="#（3）使用BNN进行推理：" class="headerlink" title="（3）使用BNN进行推理："></a>（3）使用BNN进行推理：</h6><p>根据上面的贝叶斯置信网络图，有下面情况：<br><img src="http://upload-images.jianshu.io/upload_images/3341358-bc19e263319b348d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_04.png"><br><img src="http://upload-images.jianshu.io/upload_images/3341358-b9d40731e3d646db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5_05.png"></p>
<h6 id="（4）BNN的特点："><a href="#（4）BNN的特点：" class="headerlink" title="（4）BNN的特点："></a>（4）BNN的特点：</h6><blockquote>
<p>构造网络比较费时，但网络结构一旦确定下来，添加新变量就变得容易。<br>很适合处理不完整数据，对有属性遗漏的可以通过概率或求积分来加以处理。<br>数据和先验知识结合起来，该方法对于模型的过拟合问题是非常鲁棒的。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、k-最近邻&quot;&gt;&lt;a href=&quot;#一、k-最近邻&quot; class=&quot;headerlink&quot; title=&quot;一、k-最近邻&quot;&gt;&lt;/a&gt;一、k-最近邻&lt;/h4&gt;&lt;h5 id=&quot;1、算法&quot;&gt;&lt;a href=&quot;#1、算法&quot; class=&quot;headerlink&quot; title=&quot;1、算法&quot;&gt;&lt;/a&gt;1、算法&lt;/h5&gt;&lt;p&gt;积极学习方法（eager learner）：通过训练样本建立模型。&lt;br&gt;消极学习方法（lazy learner）：实例的学习，k-最近邻就属于这种。&lt;/p&gt;
&lt;h6 id=&quot;k-最近邻算法：&quot;&gt;&lt;a href=&quot;#k-最近邻算法：&quot; class=&quot;headerlink&quot; title=&quot;k-最近邻算法：&quot;&gt;&lt;/a&gt;k-最近邻算法：&lt;/h6&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;令k是最近邻数目，D是训练样例集合&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; z &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; 样例集合:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  计算 z 和每个样例 (x,y) 的距离 d&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  选择离 z 前 k 个近距离的点，为集合 Dt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  z的标记 y 为 Dt 中类较多的&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="分类算法" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>分类（1）：决策树与模型评估</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_classfy_01/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_classfy_01/</id>
    <published>2017-02-15T12:57:50.000Z</published>
    <updated>2017-02-15T13:53:06.090Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、如何建立决策树"><a href="#一、如何建立决策树" class="headerlink" title="一、如何建立决策树"></a>一、如何建立决策树</h3><h4 id="1、Hunt算法"><a href="#1、Hunt算法" class="headerlink" title="1、Hunt算法"></a>1、Hunt算法</h4><p>Hunt算法是许多决策树算法的基础，包括ID3、C4.5、CART。<br>Hunt算法步骤：</p>
<blockquote>
<p>（1）如果Dt中所有数据都属于同一个类yt，则t是叶结点，用yt标记。<br>（2）如果Dt中包含属于多个类的数据，则选择一个属性，将数据划分为较小子集。创建子女结点，将数据按属性放入子女结点中，然后递归调用该算法。</p>
</blockquote>
<p>但是该算法对于大多数情况太苛刻了，需要附加：</p>
<blockquote>
<p>（1）没有可以选择的属性，则该结点为叶结点，类标号为父结点上较多数的类。<br>（2）如果与Dt相关的数据均为同一个属性，则不可以继续划分，类标号为多数类。</p>
</blockquote>
<a id="more"></a>
<h4 id="2、属性划分"><a href="#2、属性划分" class="headerlink" title="2、属性划分"></a>2、属性划分</h4><h6 id="（1）标称变量"><a href="#（1）标称变量" class="headerlink" title="（1）标称变量"></a>（1）标称变量</h6><p>标称变量，二元划分和多路划分。CART只产生二元划分，考虑k个属性的二元划分有$2^{k-1}-1$种方法。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-4a413987d4132bf5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4_01.png"></p>
<h6 id="（2）有序变量"><a href="#（2）有序变量" class="headerlink" title="（2）有序变量"></a>（2）有序变量</h6><p>有序变量，也可以是二元划分和多路划分，但是不能违背有序性。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-257b4c916aa27474.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4_02.png"></p>
<h4 id="3、属性划分标准"><a href="#3、属性划分标准" class="headerlink" title="3、属性划分标准"></a>3、属性划分标准</h4><p>选择最佳划分的度量是根据划分后子女结点的不纯度度量。不纯度越低（纯度越高！），划分效果越好。</p>
<h6 id="（1）不纯度度量："><a href="#（1）不纯度度量：" class="headerlink" title="（1）不纯度度量："></a>（1）不纯度度量：</h6><p>$$Entropy(t)=-\sum_{i=0}^{c-1}p(i|t)log_{2}p(i|t),Entropy(t)\in[0,1]$$<br>$$Gini(t)=1-\sum_{i=0}^{c-1}[p(i|t)]^{2},Gini(t)\in[0,0.5]$$<br>$$ClassificationError(t)=1-max_{i}[p(i|t)],ClassificationError(t)\in[0,0.5]$$<br><img src="http://upload-images.jianshu.io/upload_images/3341358-3c0a745245ba6bbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4_03.png"><br>三个度量方法都是希望取值越小越好（越纯）。</p>
<h6 id="（2）结点度量："><a href="#（2）结点度量：" class="headerlink" title="（2）结点度量："></a>（2）结点度量：</h6><p>为了确定测试结点效果，我们比较父节点（划分前）、子女结点（划分后）的不纯度变化。<br><strong>信息增益：</strong><br>$$\Delta = I(parent)-\sum_{j=1}^{k}\frac{N(v_{j})}{N}I(v_{j})$$<br>其中 $I$ 为不纯度的度量，关于 $N$ 的计算是划分后的个数加权。<br>$I$ 为熵（Entropy）的时候，$\Delta$ 为信息增益。<br><strong>信息增益率（Gain Ratio）：</strong><br>$$GainRatio=\frac{\Delta_{info}}{SplitInfo}=\frac{\Delta_{info}}{-\sum_{i=0}^{c-1}p(i)log_{2}p(i)}$$<br>使用信息增益率，好处是把属性测试条件产生的输出数也考虑进去。说明如果某个属性产生了大量的划分，它的划分信息会很大，从而降低了增益率。<br><strong><em>注：信息增益、信息增益率，我们希望越大越好，表示变化。</em></strong></p>
<h6 id="（3）连续变量的划分："><a href="#（3）连续变量的划分：" class="headerlink" title="（3）连续变量的划分："></a>（3）连续变量的划分：</h6><p>先对数据进行排序后，按照离散点的取值计算。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-62b82142cf5b135e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4_04.png"><br>Gini和熵趋向于有大量不同值的属性。</p>
<h4 id="4、决策树算法"><a href="#4、决策树算法" class="headerlink" title="4、决策树算法"></a>4、决策树算法</h4><h6 id="（1）决策树归纳算法："><a href="#（1）决策树归纳算法：" class="headerlink" title="（1）决策树归纳算法："></a>（1）决策树归纳算法：</h6><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">TreeGrowth(E,F):</div><div class="line">  if stopping_cond(E,F)=true then</div><div class="line">    leaf = createNode()</div><div class="line">    leaf.label = Classify(E)</div><div class="line">    return leaf</div><div class="line">  else</div><div class="line">    root = createNode()</div><div class="line">    root.test_cond = find_best_split(E,F)</div><div class="line">    令V=&#123;v|v是root.test_cond集合&#125;</div><div class="line">    for v in V do</div><div class="line">      Ev = &#123;e|v条件下的数据集合&#125;</div><div class="line">      child = TreeGrowth(Ev,F)</div><div class="line">      将child添加到树中去，将边(root-&gt;child)标记为v</div><div class="line">  return root</div></pre></td></tr></table></figure>
<h6 id="（2）决策树特点："><a href="#（2）决策树特点：" class="headerlink" title="（2）决策树特点："></a>（2）决策树特点：</h6><p>1、是一种非参数方法，不要求任何的先验假设。<br>2、找到最佳的决策树是NP完全问题。<br>3、相对容易解释。<br>4、对于噪声有相当好的鲁棒性。<br>5、冗余属性不会对决策树准确率造成影响。即为强相关性，一个用于划分，另一个则将被忽略。相反，不相关的属性，可能在构建树的过程中被偶然选中，导致决策树过于庞大。<br>6、数据碎片问题。当深度越深的时候，数据可能会太少，从而不能做出有统计意义的判断，当样本量小于某个阈值的时候，应该停止分裂。<br>7、子树可能在决策树中重复多次，显得复杂，难以解释。</p>
<h6 id="（3）斜决策树（oblique-decision-tree）："><a href="#（3）斜决策树（oblique-decision-tree）：" class="headerlink" title="（3）斜决策树（oblique decision tree）："></a>（3）斜决策树（oblique decision tree）：</h6><p>这里涉及到的决策树都是每次选取一个变量分子集划分，对某些数据集（连续属性有着复杂建模）缺乏划分能力。<br>斜决策树可以克服这个问题。<br><img src="http://upload-images.jianshu.io/upload_images/3341358-208cab6618206bf6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4_05.png"><br>测试条件为：<br>$$ x+y&lt;1$$<br>另一种方法是，构造归纳法（constructive induction），该方法创建复合属性，代表已有的属性的算术、逻辑组合。<br>构造归纳的花费较低，而斜决策树要动态的确定属性组合，但构造归纳会产生冗余属性。</p>
<h4 id="5、模型过拟合"><a href="#5、模型过拟合" class="headerlink" title="5、模型过拟合"></a>5、模型过拟合</h4><p>分类模型误差分为：训练误差（training error）、泛化误差（generalization error）。<br>一个好的模型需要有较低的泛化误差和训练误差。</p>
<h6 id="奥卡姆剃刀（Occam’s-razor）："><a href="#奥卡姆剃刀（Occam’s-razor）：" class="headerlink" title="奥卡姆剃刀（Occam’s razor）："></a>奥卡姆剃刀（Occam’s razor）：</h6><p>给定两个具有相同泛化误差的模型，较简单的模型比较复杂的模型更可取。</p>
<h6 id="悲观误差估计（pessimistic-error-estimate）："><a href="#悲观误差估计（pessimistic-error-estimate）：" class="headerlink" title="悲观误差估计（pessimistic error estimate）："></a>悲观误差估计（pessimistic error estimate）：</h6><p>$$e_{g}(T)=\frac{\sum_{i=1}^{k}[e(t_{i})+\Omega (t_{i})]}{\sum_{i=1}^{k}n(t_{i})}=\frac{e(T)+\Omega(T)}{N_{t}}$$<br>$k$是决策树的<strong>叶节点</strong>数目，$e(T)$为总训练误差，$N_{t}$为总训练样本数，$\Omega$为罚项。<br>对二叉树来说，0.5的罚项意味着只要至少能够改善一个训练记录分类，结点就应当扩展，当1位罚项，意味着除非能够减少一个以上训练记录的误分类，否则结点不应当扩展。</p>
<h6 id="先剪枝："><a href="#先剪枝：" class="headerlink" title="先剪枝："></a>先剪枝：</h6><p>当达到某个条件，提前终止。例如：当观察到某个不纯度度量低于某个确定阈值时就停止扩展叶结点，但是，难点在于很难确定正确终止的阈值。</p>
<h6 id="后剪枝："><a href="#后剪枝：" class="headerlink" title="后剪枝："></a>后剪枝：</h6><p>初始按照最大规模生长，按照自底向上修剪决策树。修剪方式：<br>（1）子树替换（subtree replacement）用叶结点替代子树，叶结点的类标号为子树的多数类；<br>（2）子树提升（subtree raising）子树中最常使用的分支替代子树。后剪枝能产生更好的结果。</p>
<h4 id="6、评估分类器性能"><a href="#6、评估分类器性能" class="headerlink" title="6、评估分类器性能"></a>6、评估分类器性能</h4><h6 id="自助法（bootstrap）："><a href="#自助法（bootstrap）：" class="headerlink" title="自助法（bootstrap）："></a>自助法（bootstrap）：</h6><p>训练集是对于原数据集的有放回抽样，如果原始数据集$N$，可以证明，大小为$N$的自助样本大约包含原数据63.2%的记录。当$N$充分大的时候，$1-(1-\frac{1}{N})^{N}$ 概率逼近 $1-e^{-1}=0.632$。抽样 $b$ 次，产生 $b$ 个bootstrap样本，则，总准确率为（$acc_{s}$为包含所有样本计算的准确率）：<br>$$ acc_{boot}=\frac{1}{b}\sum_{i=1}^{b}(0.632\times\varepsilon _{i}+0.368\times acc_{s})$$</p>
<h6 id="准确度的区间估计："><a href="#准确度的区间估计：" class="headerlink" title="准确度的区间估计："></a>准确度的区间估计：</h6><p>将分类问题看做二项分布，则有：<br>令 $X $为模型正确分类，$p$ 为准确率，$X $服从均值 $Np$、方差 $Np(1-p)$的二项分布。$acc=\frac{X}{N}$为均值 $p$，方差 $\frac{p(1-p)}{N}$ 的二项分布。$acc$ 的置信区间：<br>$$ P\left(-Z_{\frac{\alpha }{2}} \leq \frac{acc-p}{\sqrt{p(1-p)/N}} \leq Z_{1-\frac{\alpha}{2}}\right)=1-\alpha$$<br>$$ P\in\frac{2\times N \times acc +Z_{\frac{\alpha}{2}}^{2}\pm Z_{\frac{\alpha}{2}}\sqrt{Z_{\frac{\alpha}{2}}^{2}+4\times N \times acc-4\times N \times acc^{2}}}{2(N+Z_{\frac{\alpha}{2}}^{2})}$$</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、如何建立决策树&quot;&gt;&lt;a href=&quot;#一、如何建立决策树&quot; class=&quot;headerlink&quot; title=&quot;一、如何建立决策树&quot;&gt;&lt;/a&gt;一、如何建立决策树&lt;/h3&gt;&lt;h4 id=&quot;1、Hunt算法&quot;&gt;&lt;a href=&quot;#1、Hunt算法&quot; class=&quot;headerlink&quot; title=&quot;1、Hunt算法&quot;&gt;&lt;/a&gt;1、Hunt算法&lt;/h4&gt;&lt;p&gt;Hunt算法是许多决策树算法的基础，包括ID3、C4.5、CART。&lt;br&gt;Hunt算法步骤：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）如果Dt中所有数据都属于同一个类yt，则t是叶结点，用yt标记。&lt;br&gt;（2）如果Dt中包含属于多个类的数据，则选择一个属性，将数据划分为较小子集。创建子女结点，将数据按属性放入子女结点中，然后递归调用该算法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是该算法对于大多数情况太苛刻了，需要附加：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）没有可以选择的属性，则该结点为叶结点，类标号为父结点上较多数的类。&lt;br&gt;（2）如果与Dt相关的数据均为同一个属性，则不可以继续划分，类标号为多数类。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="分类算法" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>数据</title>
    <link href="http://yoursite.com/2017/02/15/ML_ITDM_data/"/>
    <id>http://yoursite.com/2017/02/15/ML_ITDM_data/</id>
    <published>2017-02-15T12:47:32.000Z</published>
    <updated>2017-02-15T13:53:23.231Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、数据知识"><a href="#一、数据知识" class="headerlink" title="一、数据知识"></a>一、数据知识</h4><p>如果若干属性是强相关的，则说明这些属性可能提供了高度冗余的信息，我们可以决定只保留一个。</p>
<h4 id="二、数据预处理"><a href="#二、数据预处理" class="headerlink" title="二、数据预处理"></a>二、数据预处理</h4><h5 id="1、维规约："><a href="#1、维规约：" class="headerlink" title="1、维规约："></a>1、维规约：</h5><p>通过创建新属性，将一些旧属性合并在一起来降低数据的维度。通过选择旧属性的子集得到的新属性，这种维规约称为特征子集选择。<br><a id="more"></a></p>
<h5 id="2、维灾难："><a href="#2、维灾难：" class="headerlink" title="2、维灾难："></a>2、维灾难：</h5><p>数据维度（属性）过高。数据稀疏，对于分类，没有足够多的数据用于建模；对于聚类，点之间的密度和距离定义失去了意义，分类准确率降低。</p>
<h5 id="3、数据离散化："><a href="#3、数据离散化：" class="headerlink" title="3、数据离散化："></a>3、数据离散化：</h5><p>将连续型变量离散化为离散型变量。</p>
<h6 id="（1）非监督离散化："><a href="#（1）非监督离散化：" class="headerlink" title="（1）非监督离散化："></a>（1）非监督离散化：</h6><p><img src="http://upload-images.jianshu.io/upload_images/3341358-1454dcb18146b13a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="2_01.png"></p>
<p><em>这里注意K均值离散化是什么样的技术，去寻找资料。</em></p>
<h6 id="（2）监督离散化："><a href="#（2）监督离散化：" class="headerlink" title="（2）监督离散化："></a>（2）监督离散化：</h6><p>计算熵，希望获得最小的熵：</p>
<p>$$ e_{i}=-\sum_{k}^{j=1}p_{ij}*log_{2}(p_{ij}) $$</p>
<p>$$ e=\sum_{i=1}^{n}w_{i}e_{i} $$ </p>
<p>其中e为该区间的熵。<br>若纯：对于$p_{ij} = 0$或者1，$e_{i} = 0$<br>若不纯：则熵最大。</p>
<h5 id="4、变量变换"><a href="#4、变量变换" class="headerlink" title="4、变量变换"></a>4、变量变换</h5><p>标准化：创建一个变量，使得它有均值为0，标准差为1</p>
<p>$$ x’=\frac{x-\bar{x}}{s_{x}} $$ </p>
<p>均值和标准差受离群点的影响很大，通常需要使用其他变化，用中位数（median）代替均值，使用绝对标准差（absolute standard deviation）取代标准差。绝对标准差：</p>
<p>$$ \sigma_{A}=\sum_{i=1}^{m}\left|x_{i}-\mu\right| $$ </p>
<h4 id="三、属性的相似度和相异度"><a href="#三、属性的相似度和相异度" class="headerlink" title="三、属性的相似度和相异度"></a>三、属性的相似度和相异度</h4><h5 id="1、相异度，距离"><a href="#1、相异度，距离" class="headerlink" title="1、相异度，距离"></a>1、相异度，距离</h5><p>闵可夫斯基距离（Minkowski distance）：</p>
<p>$$ d(x,y)=\left(\sum_{k=1}^{n}\left|x_{k}-y_{k}\right|^{r}\right)^{\frac{1}{r}} $$ </p>
<p>注：$r=1$时，曼哈顿距离。$r=2$时，欧几里得距离。r=无穷时，上确界距离。<br>距离的性质：<br>（1）非负性；（2）对称性；（3）三角不等式。</p>
<h5 id="2、相似度"><a href="#2、相似度" class="headerlink" title="2、相似度"></a>2、相似度</h5><h6 id="（1）简单匹配系数（Simple-Matching-Coefficient，SMC）"><a href="#（1）简单匹配系数（Simple-Matching-Coefficient，SMC）" class="headerlink" title="（1）简单匹配系数（Simple Matching Coefficient，SMC）"></a>（1）简单匹配系数（Simple Matching Coefficient，SMC）</h6><p>$$ SMC=\frac{f_{11}+f_{00}}{f_{01}+f_{10}+f_{11}+f_{00}} $$ </p>
<p>其中$f_{11}$表示：x取1并且y取1的属性个数。其他类似。SMC可以是一个仅包含<strong>是非题</strong>的检测中用来发现回答问题相似的学生。</p>
<h6 id="（2）Jaccard系数"><a href="#（2）Jaccard系数" class="headerlink" title="（2）Jaccard系数"></a>（2）Jaccard系数</h6><p>$$ J=\frac{f_{11}}{f_{01}+f_{10}+f_{11}} $$ </p>
<p>以上两个系数，均用于二元变量，0-1的计算。</p>
<h6 id="（3）余弦相似度"><a href="#（3）余弦相似度" class="headerlink" title="（3）余弦相似度"></a>（3）余弦相似度</h6><p>$$ cos(x,y)=\frac{x\cdot y}{\left | x \right |\left | y \right |}=\frac{x}{\left|x\right|}\cdot \frac{y}{\left|y\right|}=x’\cdot y’ $$ </p>
<p>余弦相似度从等式右边，可以看出不需要考虑量值。其中，有向量点积计算公式：</p>
<p>$$ x\cdot y=\sum_{n}^{k=1}x_{k}y_{k},\left | x \right |=\sqrt{\sum_{n}^{k=1}x_{k}^{2}}=\sqrt{x\cdot x} $$ </p>
<h6 id="（4）广义Jaccard系数（Tanimoto系数，EJ）"><a href="#（4）广义Jaccard系数（Tanimoto系数，EJ）" class="headerlink" title="（4）广义Jaccard系数（Tanimoto系数，EJ）"></a>（4）广义Jaccard系数（Tanimoto系数，EJ）</h6><p>$$ EJ(x,y)=\frac{x\cdot y}{\left | x \right |^{2}+\left | y \right |^{2}-x\cdot y}$$ </p>
<h6 id="（5）相关性"><a href="#（5）相关性" class="headerlink" title="（5）相关性"></a>（5）相关性</h6><p>Pearson相关系数，[-1,1]之间：</p>
<p>$$ corr(x,y)=\frac{S_{xy}}{S_{x}S_{y}}=\frac{\frac{1}{n-1}\sum_{k=1}^{n}(x_{k}-\bar{x})(y_{k}-\bar{y})}{\sqrt{\frac{1}{n-1}\sum_{k=1}^{n}(x_{k}-\bar{x})^{2}}\cdot \sqrt{\frac{1}{n-1}\sum_{k=1}^{n}(y_{k}-\bar{y})^{2}}}$$ </p>
<p>Bregman散度：<br>失真函数，损失函数。y为原来的点，x为某个失真值。给定一个严格凸函数，Bregman散度D（x，y）：</p>
<p>$$ D(x,y)=\phi (x)+\phi (y)-\left \langle \triangledown \phi(y),(x-y) \right \rangle$$ </p>
<p>后面的为梯度和内积。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3341358-1ccfbf4c5fc680d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="2_02.png"></p>
<p>$y=1$时，在$x=2$和$x=3$上的Bregman散度。</p>
<h6 id="（6）马氏距离（Mahalanobis距离）"><a href="#（6）马氏距离（Mahalanobis距离）" class="headerlink" title="（6）马氏距离（Mahalanobis距离）"></a>（6）马氏距离（Mahalanobis距离）</h6><p>$$ mahalanobis(x,y)=(x-y)\Sigma ^{-1}(x-y)^{T}$$ </p>
<p>x，y为两个点，中间的为数据协方差的逆。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、数据知识&quot;&gt;&lt;a href=&quot;#一、数据知识&quot; class=&quot;headerlink&quot; title=&quot;一、数据知识&quot;&gt;&lt;/a&gt;一、数据知识&lt;/h4&gt;&lt;p&gt;如果若干属性是强相关的，则说明这些属性可能提供了高度冗余的信息，我们可以决定只保留一个。&lt;/p&gt;
&lt;h4 id=&quot;二、数据预处理&quot;&gt;&lt;a href=&quot;#二、数据预处理&quot; class=&quot;headerlink&quot; title=&quot;二、数据预处理&quot;&gt;&lt;/a&gt;二、数据预处理&lt;/h4&gt;&lt;h5 id=&quot;1、维规约：&quot;&gt;&lt;a href=&quot;#1、维规约：&quot; class=&quot;headerlink&quot; title=&quot;1、维规约：&quot;&gt;&lt;/a&gt;1、维规约：&lt;/h5&gt;&lt;p&gt;通过创建新属性，将一些旧属性合并在一起来降低数据的维度。通过选择旧属性的子集得到的新属性，这种维规约称为特征子集选择。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="数据挖掘导论" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>cmd设置命令缓存（伪别名）</title>
    <link href="http://yoursite.com/2017/02/14/windows_bat_alias/"/>
    <id>http://yoursite.com/2017/02/14/windows_bat_alias/</id>
    <published>2017-02-14T12:34:00.000Z</published>
    <updated>2017-02-15T12:56:38.019Z</updated>
    
    <content type="html"><![CDATA[<p>1、创建一个bat文件，alias.bat，内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">doskey ls=dir</div><div class="line">doskey python3=C:\Users\xxxx\Anaconda3\python.exe</div><div class="line">doskey pip3=C:\Users\xxxx\Anaconda3\Scripts\pip.exe</div></pre></td></tr></table></figure></p>
<p>2、该文件保存于任意目录下，目录最好为英文，C:\Users\xxxx。<br>3、win+r，输入regedit，打开注册表。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">HKEY_LOCAL_MACHINE\Software\Microsoft\Command</div><div class="line">HKEY_CURRENT_USER\Software\Microsoft\Command</div></pre></td></tr></table></figure></p>
<p><img src="/pictures/pic_20170214_2343.png" alt="图片未加载" title="pic_20170214_2343.png"></p>
<a id="more"></a>
<p>不过，可能没有AutoRun这个键，可以自己添加：右键——新建——字符串值，输入“AutoRun”，然后选中——右键——修改，把路径输入进去，大概像上图那样，然后关掉就可以了（这里我只改了CURRENT_USER的，没改HKEY_LOCAL_MACHINE，因为我觉得这样基本就够用了）</p>
<p>但是。这只是建立一个缓存，并不是真正意义上的别名。<br>自己尝试过只能直接使用“别名”，不能在“别名”的后面添加别的参数。如：<code>pip3 list</code>不能列出已安装的包，只能显示<code>pip</code>的帮助，相当于仅仅在命令行里输入<br><code>C:\Users\xxxx\Anaconda3\Scripts\pip.exe</code>，<br>而不是<code>C:\Users\xxxx\Anaconda3\Scripts\pip.exe list</code>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1、创建一个bat文件，alias.bat，内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;doskey ls=dir&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;doskey python3=C:\Users\xxxx\Anaconda3\python.exe&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;doskey pip3=C:\Users\xxxx\Anaconda3\Scripts\pip.exe&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2、该文件保存于任意目录下，目录最好为英文，C:\Users\xxxx。&lt;br&gt;3、win+r，输入regedit，打开注册表。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;HKEY_LOCAL_MACHINE\Software\Microsoft\Command&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;HKEY_CURRENT_USER\Software\Microsoft\Command&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/pictures/pic_20170214_2343.png&quot; alt=&quot;图片未加载&quot; title=&quot;pic_20170214_2343.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Windows" scheme="http://yoursite.com/categories/Windows/"/>
    
    
      <category term="Windows" scheme="http://yoursite.com/tags/Windows/"/>
    
      <category term="bat" scheme="http://yoursite.com/tags/bat/"/>
    
  </entry>
  
  <entry>
    <title>awk</title>
    <link href="http://yoursite.com/2017/01/24/linux_awk/"/>
    <id>http://yoursite.com/2017/01/24/linux_awk/</id>
    <published>2017-01-24T12:37:00.000Z</published>
    <updated>2017-02-15T12:53:54.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、简单例子"><a href="#1、简单例子" class="headerlink" title="1、简单例子"></a>1、简单例子</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">awk  &apos;BEGIN &#123;print &quot;Hello world!&quot;&#125;&apos;        # 这个不需要文件输入就可以</div></pre></td></tr></table></figure>
<p><code>awkscr</code>文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/^$/ &#123;print &quot;This is a blank line&quot;&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>运行脚本文件<code>awkscr</code>对应于<code>test</code>文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">awk -f awkscr test</div></pre></td></tr></table></figure></p>
<p>例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo a b c d | awk &apos;&#123;one=1;two=2&#125;&#123;print $(one + two)&#125;&apos;</div></pre></td></tr></table></figure></p>
<blockquote>
<p>-F “\t” ：表示分隔符为\t<br>FS：表示分隔符</p>
</blockquote>
<p>灵活指定分隔符，正则指定<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">BEGIN &#123;FS=&quot;,&quot;&#125;&#123;print $1  &quot;,&quot;  $6&#125;   # 使用，为分隔符</div><div class="line">FS=&quot;\t&quot;                # 指定一个 tab 为分隔符</div><div class="line">FS=&quot;\t+&quot;              # 指定一个以上的 tab 为分隔符【正则】</div><div class="line">FS=&quot;[&apos;:\t]&quot;            # 指定&apos;、:、 tab 中任何一个为分隔符</div></pre></td></tr></table></figure></p>
<h4 id="2、模式匹配"><a href="#2、模式匹配" class="headerlink" title="2、模式匹配"></a>2、模式匹配</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">awk &apos;/^$/ &#123;print &quot;This is a blank line&quot;&#125;&apos;  test</div><div class="line">awk &apos;/[0-9]/ &#123;print &quot;This is a blank line&quot;&#125;&apos;  test</div><div class="line">awk &apos;/[A-Za-z]/ &#123;print &quot;This is a blank line&quot;&#125;&apos;  test</div></pre></td></tr></table></figure>
<p><a href="http://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858470.html" target="_blank" rel="external">http://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858470.html</a></p>
<p><a href="http://awk.readthedocs.io/en/latest/chapter-one.html" target="_blank" rel="external">http://awk.readthedocs.io/en/latest/chapter-one.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1、简单例子&quot;&gt;&lt;a href=&quot;#1、简单例子&quot; class=&quot;headerlink&quot; title=&quot;1、简单例子&quot;&gt;&lt;/a&gt;1、简单例子&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;awk  &amp;apos;BEGIN &amp;#123;print &amp;quot;Hello world!&amp;quot;&amp;#125;&amp;apos;        # 这个不需要文件输入就可以&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;awkscr&lt;/code&gt;文件：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;/^$/ &amp;#123;print &amp;quot;This is a blank line&amp;quot;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>sz-rz-文件传输</title>
    <link href="http://yoursite.com/2017/01/24/linux_03_rzsz/"/>
    <id>http://yoursite.com/2017/01/24/linux_03_rzsz/</id>
    <published>2017-01-24T12:36:00.000Z</published>
    <updated>2017-02-15T12:53:47.114Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Xshell"><a href="#Xshell" class="headerlink" title="Xshell"></a>Xshell</h3><h4 id="1、sz用法（下载）："><a href="#1、sz用法（下载）：" class="headerlink" title="1、sz用法（下载）："></a>1、sz用法（下载）：</h4><p>下载一个文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sz filename</div></pre></td></tr></table></figure></p>
<p>下载多个文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sz filename1 filename2</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>下载dir目录下的所有文件，不包含dir下的文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sz dir/*</div></pre></td></tr></table></figure></p>
<h4 id="2、rz用法（上传）："><a href="#2、rz用法（上传）：" class="headerlink" title="2、rz用法（上传）："></a>2、rz用法（上传）：</h4><p>输入rz回车后，会出现文件选择对话框，选择需要上传文件，一次可以指定多个文件，上传到服务器的路径为当前执行rz命令的目录。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Xshell&quot;&gt;&lt;a href=&quot;#Xshell&quot; class=&quot;headerlink&quot; title=&quot;Xshell&quot;&gt;&lt;/a&gt;Xshell&lt;/h3&gt;&lt;h4 id=&quot;1、sz用法（下载）：&quot;&gt;&lt;a href=&quot;#1、sz用法（下载）：&quot; class=&quot;headerlink&quot; title=&quot;1、sz用法（下载）：&quot;&gt;&lt;/a&gt;1、sz用法（下载）：&lt;/h4&gt;&lt;p&gt;下载一个文件&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;sz filename&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;下载多个文件&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;sz filename1 filename2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
</feed>
